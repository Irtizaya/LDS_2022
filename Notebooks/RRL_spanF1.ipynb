{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ia9-d5mmFu0d",
        "outputId": "3d94636b-6279-4a0e-e056-49fcadaf6d7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.21.0-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 39.2 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 68.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 59.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 12.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.21.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting allennlp\n",
            "  Downloading allennlp-2.10.0-py3-none-any.whl (729 kB)\n",
            "\u001b[K     |████████████████████████████████| 729 kB 32.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.7)\n",
            "Collecting wandb<0.13.0,>=0.10.0\n",
            "  Downloading wandb-0.12.21-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 55.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62 in /usr/local/lib/python3.7/dist-packages (from allennlp) (4.64.0)\n",
            "Collecting jsonnet>=0.10.0\n",
            "  Downloading jsonnet-0.18.0.tar.gz (592 kB)\n",
            "\u001b[K     |████████████████████████████████| 592 kB 71.3 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 54.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.7.3)\n",
            "Collecting transformers<4.21,>=4.1\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 58.4 MB/s \n",
            "\u001b[?25hCollecting protobuf==3.20.0\n",
            "  Downloading protobuf-3.20.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 56.8 MB/s \n",
            "\u001b[?25hCollecting lmdb>=1.2.1\n",
            "  Downloading lmdb-1.3.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (298 kB)\n",
            "\u001b[K     |████████████████████████████████| 298 kB 65.2 MB/s \n",
            "\u001b[?25hCollecting rich==12.1\n",
            "  Downloading rich-12.1.0-py3-none-any.whl (229 kB)\n",
            "\u001b[K     |████████████████████████████████| 229 kB 68.3 MB/s \n",
            "\u001b[?25hCollecting base58>=2.1.1\n",
            "  Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
            "Collecting tensorboardX>=1.2\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 74.4 MB/s \n",
            "\u001b[?25hCollecting spacy<3.4,>=2.1.0\n",
            "  Downloading spacy-3.3.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.2 MB 69.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.3.5.1)\n",
            "Collecting cached-path<1.2.0,>=1.1.3\n",
            "  Downloading cached_path-1.1.5-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.16 in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.8.1)\n",
            "Requirement already satisfied: filelock<3.8,>=3.3 in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.7.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.0.2)\n",
            "Collecting pytest>=6.2.5\n",
            "  Downloading pytest-7.1.2-py3-none-any.whl (297 kB)\n",
            "\u001b[K     |████████████████████████████████| 297 kB 70.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: more-itertools>=8.12.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (8.13.0)\n",
            "Collecting traitlets>5.1.1\n",
            "  Downloading traitlets-5.3.0-py3-none-any.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 68.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typer>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.4.2)\n",
            "Requirement already satisfied: numpy>=1.21.4 in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.21.6)\n",
            "Collecting fairscale==0.4.6\n",
            "  Downloading fairscale-0.4.6.tar.gz (248 kB)\n",
            "\u001b[K     |████████████████████████████████| 248 kB 69.6 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting h5py>=3.6.0\n",
            "  Downloading h5py-3.7.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 58.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.1.0)\n",
            "Collecting sentencepiece>=0.1.96\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 65.2 MB/s \n",
            "\u001b[?25hCollecting torchvision<0.13.0,>=0.8.1\n",
            "  Downloading torchvision-0.12.0-cp37-cp37m-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.0 MB 1.5 MB/s \n",
            "\u001b[?25hCollecting requests>=2.28\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.5 MB/s \n",
            "\u001b[?25hCollecting torch<1.12.0,>=1.10.0\n",
            "  Downloading torch-1.11.0-cp37-cp37m-manylinux1_x86_64.whl (750.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 750.6 MB 11 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions<5.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from rich==12.1->allennlp) (4.1.1)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich==12.1->allennlp) (2.6.1)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 8.6 MB/s \n",
            "\u001b[?25hCollecting google-cloud-storage<3.0,>=1.32.0\n",
            "  Downloading google_cloud_storage-2.4.0-py2.py3-none-any.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 66.2 MB/s \n",
            "\u001b[?25hCollecting boto3<2.0,>=1.0\n",
            "  Downloading boto3-1.24.42-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 62.6 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 9.5 MB/s \n",
            "\u001b[?25hCollecting botocore<1.28.0,>=1.27.42\n",
            "  Downloading botocore-1.27.42-py3-none-any.whl (9.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.0 MB 60.5 MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.11-py2.py3-none-any.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 69.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.42->boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.8.2)\n",
            "Collecting google-cloud-core<3.0dev,>=2.3.0\n",
            "  Downloading google_cloud_core-2.3.2-py2.py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.35.0)\n",
            "Collecting google-resumable-media>=2.3.2\n",
            "  Downloading google_resumable_media-2.3.3-py2.py3-none-any.whl (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.31.6)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.15.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (21.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (2022.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.56.4)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (57.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (4.2.4)\n",
            "Collecting google-crc32c<2.0dev,>=1.0\n",
            "  Downloading google_crc32c-1.3.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.16->allennlp) (4.12.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.16->allennlp) (6.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk>=3.6.5->allennlp) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.6.5->allennlp) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.6.5->allennlp) (7.1.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (3.0.9)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (0.4.8)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=6.2.5->allennlp) (21.4.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=6.2.5->allennlp) (2.0.1)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.7/dist-packages (from pytest>=6.2.5->allennlp) (1.1.1)\n",
            "Collecting pluggy<2.0,>=0.12\n",
            "  Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: py>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from pytest>=6.2.5->allennlp) (1.11.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub>=0.0.16->allennlp) (3.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.28->allennlp) (2022.6.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.28->allennlp) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.28->allennlp) (2.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.1->allennlp) (3.1.0)\n",
            "Collecting thinc<8.1.0,>=8.0.14\n",
            "  Downloading thinc-8.0.17-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (660 kB)\n",
            "\u001b[K     |████████████████████████████████| 660 kB 70.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.11.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.4.4)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (1.0.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.0.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.0.8)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (1.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (0.9.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.3.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (0.7.8)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.0.9)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (0.6.2)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 65.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.4,>=2.1.0->allennlp) (5.2.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision<0.13.0,>=0.8.1->allennlp) (7.1.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<4.21,>=4.1->allennlp) (0.12.1)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (2.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (5.4.8)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 65.9 MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 76.7 MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.1 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.4,>=2.1.0->allennlp) (2.0.1)\n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'rich' candidate (version 12.1.0 at https://files.pythonhosted.org/packages/bc/be/1ace556afa0cf17599c2a631b04b280ae7502a9cf942c47fd66ca9ab5134/rich-12.1.0-py3-none-any.whl#sha256=b60ff99f4ff7e3d1d37444dee2b22fdd941c622dbc37841823ec1ce7f058b263 (from https://pypi.org/simple/rich/) (requires-python:>=3.6.2,<4.0.0))\n",
            "Reason for being yanked: Broken dependencies. Please upgrade to 12.2.0 or later\u001b[0m\n",
            "Building wheels for collected packages: fairscale, jsonnet, pathtools, sacremoses\n",
            "  Building wheel for fairscale (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.6-py3-none-any.whl size=307252 sha256=5b71e6dac68aa06f0a85a4c6b5d1efa290976df8a6d0ffd65f7a52a7b815dfe0\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/4f/0b/94c29ea06dfad93260cb0377855f87b7b863312317a7f69fe7\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.18.0-cp37-cp37m-linux_x86_64.whl size=3994689 sha256=0ed81945f05764b9afb2b525535cd9939577d18121546fbd26490cd8c909e486\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/63/f9/a653f9c21575e6ff271ee6a49939aa002005174cea6c35919d\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=2db6b00fd12fa6b178540c0ecb117cecdb69a99ef71719454320f38f8c90fea5\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=838278169af5f42ecbb332264351951f474605824014aecd82d2ccba4144a118\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built fairscale jsonnet pathtools sacremoses\n",
            "Installing collected packages: urllib3, protobuf, requests, jmespath, smmap, google-crc32c, botocore, s3transfer, pydantic, google-resumable-media, google-cloud-core, gitdb, commonmark, torch, thinc, shortuuid, setproctitle, sentry-sdk, rich, pluggy, pathtools, google-cloud-storage, GitPython, docker-pycreds, boto3, wandb, transformers, traitlets, torchvision, tensorboardX, spacy, sentencepiece, sacremoses, pytest, lmdb, jsonnet, h5py, fairscale, cached-path, base58, allennlp\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.9.1\n",
            "    Uninstalling pydantic-1.9.1:\n",
            "      Successfully uninstalled pydantic-1.9.1\n",
            "  Attempting uninstall: google-resumable-media\n",
            "    Found existing installation: google-resumable-media 0.4.1\n",
            "    Uninstalling google-resumable-media-0.4.1:\n",
            "      Successfully uninstalled google-resumable-media-0.4.1\n",
            "  Attempting uninstall: google-cloud-core\n",
            "    Found existing installation: google-cloud-core 1.0.3\n",
            "    Uninstalling google-cloud-core-1.0.3:\n",
            "      Successfully uninstalled google-cloud-core-1.0.3\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.0+cu113\n",
            "    Uninstalling torch-1.12.0+cu113:\n",
            "      Successfully uninstalled torch-1.12.0+cu113\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.1.0\n",
            "    Uninstalling thinc-8.1.0:\n",
            "      Successfully uninstalled thinc-8.1.0\n",
            "  Attempting uninstall: pluggy\n",
            "    Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Attempting uninstall: google-cloud-storage\n",
            "    Found existing installation: google-cloud-storage 1.18.1\n",
            "    Uninstalling google-cloud-storage-1.18.1:\n",
            "      Successfully uninstalled google-cloud-storage-1.18.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.21.0\n",
            "    Uninstalling transformers-4.21.0:\n",
            "      Successfully uninstalled transformers-4.21.0\n",
            "  Attempting uninstall: traitlets\n",
            "    Found existing installation: traitlets 5.1.1\n",
            "    Uninstalling traitlets-5.1.1:\n",
            "      Successfully uninstalled traitlets-5.1.1\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.13.0+cu113\n",
            "    Uninstalling torchvision-0.13.0+cu113:\n",
            "      Successfully uninstalled torchvision-0.13.0+cu113\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.4.1\n",
            "    Uninstalling spacy-3.4.1:\n",
            "      Successfully uninstalled spacy-3.4.1\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "  Attempting uninstall: lmdb\n",
            "    Found existing installation: lmdb 0.99\n",
            "    Uninstalling lmdb-0.99:\n",
            "      Successfully uninstalled lmdb-0.99\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.0 requires torch==1.12.0, but you have torch 1.11.0 which is incompatible.\n",
            "torchaudio 0.12.0+cu113 requires torch==1.12.0, but you have torch 1.11.0 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "nbclient 0.6.6 requires jupyter-client>=6.1.5, but you have jupyter-client 5.3.5 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.1 which is incompatible.\n",
            "google-cloud-translate 1.5.0 requires google-cloud-core<2.0dev,>=1.0.0, but you have google-cloud-core 2.3.2 which is incompatible.\n",
            "google-cloud-firestore 1.7.0 requires google-cloud-core<2.0dev,>=1.0.3, but you have google-cloud-core 2.3.2 which is incompatible.\n",
            "google-cloud-datastore 1.8.0 requires google-cloud-core<2.0dev,>=1.0.0, but you have google-cloud-core 2.3.2 which is incompatible.\n",
            "google-cloud-bigquery 1.21.0 requires google-cloud-core<2.0dev,>=1.0.3, but you have google-cloud-core 2.3.2 which is incompatible.\n",
            "google-cloud-bigquery 1.21.0 requires google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1, but you have google-resumable-media 2.3.3 which is incompatible.\n",
            "en-core-web-sm 3.4.0 requires spacy<3.5.0,>=3.4.0, but you have spacy 3.3.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed GitPython-3.1.27 allennlp-2.10.0 base58-2.1.1 boto3-1.24.42 botocore-1.27.42 cached-path-1.1.5 commonmark-0.9.1 docker-pycreds-0.4.0 fairscale-0.4.6 gitdb-4.0.9 google-cloud-core-2.3.2 google-cloud-storage-2.4.0 google-crc32c-1.3.0 google-resumable-media-2.3.3 h5py-3.7.0 jmespath-1.0.1 jsonnet-0.18.0 lmdb-1.3.0 pathtools-0.1.2 pluggy-1.0.0 protobuf-3.20.0 pydantic-1.8.2 pytest-7.1.2 requests-2.28.1 rich-12.1.0 s3transfer-0.6.0 sacremoses-0.0.53 sentencepiece-0.1.96 sentry-sdk-1.9.0 setproctitle-1.3.0 shortuuid-1.0.9 smmap-5.0.0 spacy-3.3.1 tensorboardX-2.5.1 thinc-8.0.17 torch-1.11.0 torchvision-0.12.0 traitlets-5.3.0 transformers-4.20.1 urllib3-1.26.11 wandb-0.12.21\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "requests",
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.7/dist-packages (2.4.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (2.3.2)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (1.35.0)\n",
            "Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (2.3.3)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (1.31.6)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (2.28.1)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (1.15.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (1.56.4)\n",
            "Requirement already satisfied: protobuf<4.0.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (3.20.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (2022.1)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (21.3)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (57.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.2.8)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.7/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage) (1.3.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (3.0.9)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.4.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.26.11)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2022.6.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install allennlp\n",
        "!pip install --upgrade google-cloud-storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4htMvz0ISEN",
        "outputId": "96e56687-32f7-418c-e992-d851482fb1c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "\n",
        "# %cd /content/drive/My\\ Drive/Legal\\ DS/SCRF_RRL/rhetorical-role-baseline/\n",
        "# Ekstep corpus:\n",
        "# %cd /content/drive/My\\ Drive/Legal\\ DS/Paheli_new_corpus/semantic_segmentation/Corpus\n",
        "\n",
        "import pandas as pd\n",
        "from itertools import groupby\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5axwS-V8vrR",
        "outputId": "72bde9f1-b20c-42d8-e623-34bf14fd03bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Legal DS/Paheli_new_corpus/semantic-segmentation/Corpus\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/My\\ Drive/Legal\\ DS/Paheli_new_corpus/semantic-segmentation/Corpus/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bZy61wXG0dJ",
        "outputId": "1523b8ac-d1c6-475c-f2a7-d3287c483daf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n",
            "13.4 17 11\n"
          ]
        }
      ],
      "source": [
        "#get all labels in docs\n",
        "import json\n",
        "\n",
        "#%cd /content/drive/My\\ Drive/Legal\\ DS/SCRF_RRL/rhetorical-role-baseline/\n",
        "f = open('sample_train_to_ekstep.json')\n",
        "data = json.load(f)\n",
        "\n",
        "doc_labels = []\n",
        "for example in range(len(data)):\n",
        "  sentences = data[example]['annotations'][0]['result']\n",
        "  doc_label = []\n",
        "  for sentence in sentences:\n",
        "    doc_label.append(sentence['value']['labels'][0])\n",
        "  if(len(doc_label)!=0):\n",
        "    doc_labels.append(doc_label)\n",
        "  \n",
        "print(len(doc_labels))\n",
        "\n",
        "sent_labels_len = [len(x) for x in doc_labels]\n",
        "\n",
        "avg_sent_level_labels, max_sent_labels, min_sent_labels  = sum(sent_labels_len)/len(sent_labels_len), max(sent_labels_len), min(sent_labels_len)\n",
        "print(avg_sent_level_labels, max_sent_labels, min_sent_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FE8Ml9fWTiy",
        "outputId": "6e5bdbaa-de7d-4268-fbb4-f44d3903fa68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['OBJECTIVE', 'METHODS', 'METHODS', 'METHODS', 'METHODS', 'METHODS', 'RESULTS', 'RESULTS', 'RESULTS', 'RESULTS', 'RESULTS', 'CONCLUSIONS'], ['BACKGROUND', 'BACKGROUND', 'OBJECTIVE', 'OBJECTIVE', 'METHODS', 'METHODS', 'METHODS', 'RESULTS', 'RESULTS', 'CONCLUSIONS', 'CONCLUSIONS'], ['BACKGROUND', 'BACKGROUND', 'METHODS', 'METHODS', 'METHODS', 'METHODS', 'METHODS', 'METHODS', 'RESULTS', 'RESULTS', 'RESULTS', 'CONCLUSIONS', 'CONCLUSIONS', 'CONCLUSIONS', 'BACKGROUND'], ['OBJECTIVE', 'METHODS', 'METHODS', 'METHODS', 'METHODS', 'RESULTS', 'RESULTS', 'RESULTS', 'RESULTS', 'RESULTS', 'CONCLUSIONS', 'CONCLUSIONS', 'CONCLUSIONS', 'BACKGROUND', 'BACKGROUND', 'BACKGROUND', 'BACKGROUND'], ['OBJECTIVE', 'OBJECTIVE', 'OBJECTIVE', 'OBJECTIVE', 'METHODS', 'METHODS', 'METHODS', 'RESULTS', 'RESULTS', 'RESULTS', 'CONCLUSIONS', 'CONCLUSIONS']]\n"
          ]
        }
      ],
      "source": [
        "#all labels in first doc\n",
        "print(doc_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZsMd0KyG0ks",
        "outputId": "cb39d2cc-2a2f-4cfb-9ece-0f341fd4862e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['Facts', 'Ratio of the decision', 'Facts', 'Argument', 'Facts', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Ruling by Lower Court', 'Facts', 'Ruling by Lower Court', 'Ratio of the decision', 'Precedent', 'Ruling by Lower Court', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Argument', 'Statute', 'Ratio of the decision', 'Ruling by Present Court'], ['Facts', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Facts', 'Ruling by Lower Court', 'Facts', 'Argument', 'Ruling by Lower Court', 'Argument', 'Ratio of the decision', 'Argument', 'Statute', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Argument', 'Ruling by Lower Court', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Facts', 'Precedent', 'Ratio of the decision', 'Ruling by Present Court'], ['Facts', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Facts', 'Ruling by Lower Court', 'Argument', 'Statute', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Precedent', 'Statute', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Ruling by Present Court'], ['Facts', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Facts', 'Ruling by Lower Court', 'Facts', 'Ratio of the decision', 'Argument', 'Facts', 'Ruling by Lower Court', 'Precedent', 'Ratio of the decision', 'Ruling by Present Court'], ['Facts', 'Ruling by Lower Court', 'Facts', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Ruling by Present Court', 'Ratio of the decision', 'Ruling by Present Court', 'Ratio of the decision', 'Ruling by Present Court'], ['Ratio of the decision', 'Facts', 'Argument', 'Facts', 'Statute', 'Facts', 'Ruling by Lower Court', 'Facts', 'Argument', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Ruling by Present Court'], ['Facts', 'Ruling by Lower Court', 'Facts', 'Ruling by Lower Court', 'Facts', 'Argument', 'Ruling by Lower Court', 'Facts', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Ruling by Lower Court', 'Facts', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Ruling by Present Court'], ['Facts', 'Argument', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Statute', 'Ruling by Present Court', 'Ratio of the decision', 'Ruling by Present Court'], ['Ratio of the decision', 'Facts', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Facts', 'Ruling by Lower Court', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Ruling by Lower Court', 'Ratio of the decision', 'Ruling by Lower Court', 'Ratio of the decision', 'Ruling by Present Court', 'Ratio of the decision', 'Ruling by Present Court'], ['Facts', 'Argument', 'Facts', 'Argument', 'Facts', 'Precedent', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Ruling by Present Court'], ['Ratio of the decision', 'Facts', 'Ruling by Lower Court', 'Facts', 'Argument', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Ruling by Present Court'], ['Facts', 'Ruling by Lower Court', 'Facts', 'Ruling by Lower Court', 'Facts', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Ruling by Present Court'], ['Facts', 'Statute', 'Ratio of the decision', 'Facts', 'Argument', 'Facts', 'Argument', 'Ratio of the decision', 'Facts', 'Ruling by Lower Court', 'Facts', 'Ruling by Lower Court', 'Facts', 'Argument', 'Ratio of the decision', 'Argument', 'Statute', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Precedent', 'Argument', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Ruling by Present Court'], ['Facts', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Ruling by Lower Court', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Ruling by Present Court', 'Ratio of the decision', 'Ruling by Present Court', 'Ratio of the decision', 'Ruling by Present Court'], ['Facts', 'Argument', 'Facts', 'Argument', 'Facts', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Facts', 'Ruling by Lower Court', 'Facts', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Ruling by Present Court'], ['Ratio of the decision', 'Facts', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Ruling by Lower Court', 'Facts', 'Ruling by Lower Court', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Facts', 'Ruling by Lower Court', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Precedent', 'Ruling by Present Court'], ['Facts', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Facts', 'Argument', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Ruling by Present Court', 'Ratio of the decision', 'Ruling by Present Court'], ['Facts', 'Statute', 'Argument', 'Facts', 'Precedent', 'Facts', 'Precedent', 'Facts', 'Argument', 'Precedent', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Ruling by Present Court', 'Ratio of the decision', 'Argument', 'Facts', 'Argument', 'Ratio of the decision', 'Ruling by Present Court'], ['Facts', 'Ruling by Present Court', 'Facts', 'Ratio of the decision', 'Facts', 'Ruling by Lower Court', 'Ruling by Present Court', 'Ruling by Lower Court', 'Facts', 'Ruling by Lower Court', 'Facts', 'Ruling by Lower Court', 'Facts', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Precedent', 'Ruling by Present Court', 'Ratio of the decision', 'Precedent', 'Ruling by Present Court'], ['Facts', 'Ratio of the decision', 'Facts', 'Ruling by Lower Court', 'Facts', 'Argument', 'Facts', 'Argument', 'Ratio of the decision', 'Argument', 'Statute', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Ruling by Present Court', 'Ratio of the decision', 'Argument', 'Ruling by Lower Court', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Ruling by Present Court'], ['Facts', 'Argument', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Facts', 'Argument', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Precedent', 'Facts', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Precedent', 'Facts', 'Ratio of the decision', 'Ruling by Present Court'], ['Facts', 'Argument', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Ruling by Present Court'], ['Facts', 'Statute', 'Ratio of the decision', 'Statute', 'Facts', 'Ruling by Lower Court', 'Ruling by Present Court', 'Facts', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Facts', 'Ruling by Lower Court', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Ruling by Present Court'], ['Facts', 'Argument', 'Facts', 'Ratio of the decision', 'Argument', 'Facts', 'Argument', 'Facts', 'Ruling by Lower Court', 'Argument', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Precedent', 'Statute', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Ruling by Lower Court', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Statute', 'Argument', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Ruling by Present Court'], ['Facts', 'Ruling by Lower Court', 'Facts', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Ruling by Present Court', 'Ratio of the decision', 'Ruling by Present Court'], ['Facts', 'Ratio of the decision', 'Facts', 'Ruling by Lower Court', 'Facts', 'Ratio of the decision', 'Argument', 'Ruling by Present Court', 'Ratio of the decision', 'Ruling by Present Court', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Argument', 'Precedent', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Precedent', 'Ruling by Present Court', 'Ratio of the decision', 'Argument', 'Ruling by Present Court'], ['Facts', 'Ruling by Lower Court', 'Facts', 'Argument', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Statute', 'Ruling by Lower Court', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Ruling by Present Court'], ['Facts', 'Argument', 'Precedent', 'Argument', 'Ratio of the decision', 'Facts', 'Precedent', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Ruling by Present Court', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Ruling by Present Court', 'Ratio of the decision', 'Ruling by Present Court'], ['Ratio of the decision', 'Facts', 'Ratio of the decision', 'Statute', 'Facts', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Statute', 'Argument', 'Ratio of the decision', 'Argument', 'Precedent', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Ruling by Lower Court', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Ruling by Present Court', 'Ratio of the decision', 'Ruling by Present Court'], ['Facts', 'Ruling by Lower Court', 'Facts', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Ruling by Present Court'], ['Facts', 'Argument', 'Facts', 'Ruling by Lower Court', 'Facts', 'Argument', 'Precedent', 'Argument', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Precedent', 'Ruling by Present Court'], ['Facts', 'Ratio of the decision', 'Facts', 'Ruling by Lower Court', 'Facts', 'Argument', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Argument', 'Precedent', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Statute', 'Precedent', 'Ratio of the decision', 'Ruling by Present Court'], ['Facts', 'Argument', 'Facts', 'Argument', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Argument', 'Statute', 'Ratio of the decision', 'Ruling by Lower Court', 'Ratio of the decision', 'Facts', 'Ruling by Lower Court', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Ruling by Present Court'], ['Ratio of the decision', 'Facts', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Precedent', 'Ruling by Present Court'], ['Facts', 'Argument', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Statute', 'Precedent', 'Facts', 'Precedent', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Ruling by Present Court'], ['Facts', 'Ratio of the decision', 'Facts', 'Argument', 'Facts', 'Argument', 'Facts', 'Argument', 'Ratio of the decision', 'Argument', 'Facts', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Argument', 'Precedent', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Precedent', 'Ruling by Present Court', 'Argument', 'Statute', 'Ratio of the decision', 'Statute', 'Precedent', 'Ratio of the decision', 'Ruling by Present Court'], ['Facts', 'Ruling by Lower Court', 'Facts', 'Ruling by Lower Court', 'Facts', 'Argument', 'Ratio of the decision', 'Ruling by Present Court', 'Facts', 'Ruling by Lower Court', 'Facts', 'Ruling by Lower Court', 'Facts', 'Ruling by Lower Court', 'Facts', 'Ratio of the decision', 'Ruling by Lower Court', 'Facts', 'Ruling by Present Court', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Ruling by Present Court'], ['Facts', 'Ruling by Lower Court', 'Facts', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Statute', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Ruling by Present Court'], ['Facts', 'Statute', 'Facts', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Ruling by Present Court'], ['Facts', 'Ruling by Lower Court', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Precedent', 'Statute', 'Precedent', 'Ratio of the decision', 'Ruling by Present Court']]\n",
            "22.125 45 10\n"
          ]
        }
      ],
      "source": [
        "#get all span labels\n",
        "\n",
        "from itertools import groupby\n",
        "\n",
        "span_labels = [[x[0] for x in groupby(y)] for y in doc_labels]\n",
        "\n",
        "print(span_labels)\n",
        "\n",
        "span_labels_len = [len(x) for x in span_labels]\n",
        "\n",
        "avg_span_level_labels, max_span_labels, min_span_labels  = sum(span_labels_len)/len(span_labels_len), max(span_labels_len), min(span_labels_len)\n",
        "print(avg_span_level_labels, max_span_labels, min_span_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "cRBgCgACaLiX"
      },
      "outputs": [],
      "source": [
        "from itertools import groupby"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TV2Z7cP68H3u"
      },
      "outputs": [],
      "source": [
        "#span labels and lens\n",
        "span_labels = []\n",
        "span_lens = []\n",
        "\n",
        "for i in range(len(doc_labels)):\n",
        "  span_label = []\n",
        "  span_len = []\n",
        "  prev = doc_labels[i][0]\n",
        "  cur_len = 1\n",
        "  for j in range(1,len(doc_labels[i])):\n",
        "    if(prev !=doc_labels[i][j]):\n",
        "      span_label.append(prev)\n",
        "      span_len.append(cur_len)\n",
        "      prev = doc_labels[i][j]\n",
        "      cur_len = 1\n",
        "    else:\n",
        "      cur_len = cur_len + 1\n",
        "  span_labels.append(span_label)\n",
        "  span_lens.append(span_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIPWlf_8Wq_O",
        "outputId": "8babdedb-e9b4-4a65-b687-abb78a0b7206"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Facts', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Facts', 'Ruling by Lower Court', 'Facts', 'Argument', 'Ruling by Lower Court', 'Argument', 'Ratio of the decision', 'Argument', 'Statute', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Facts', 'Ratio of the decision', 'Argument', 'Ruling by Lower Court', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Precedent', 'Ratio of the decision', 'Argument', 'Ratio of the decision', 'Facts', 'Precedent', 'Ratio of the decision']\n"
          ]
        }
      ],
      "source": [
        "print(span_labels[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgTUWA55-NvA"
      },
      "outputs": [],
      "source": [
        "\n",
        "sorted([max(sl) for sl in span_lens])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UpFSw70fMpDU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "#import torchtext\n",
        "import json\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer\n",
        "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler, KBinsDiscretizer\n",
        "import numpy as np\n",
        "# Pytorch Dataset\n",
        "class RRDataset(Dataset):\n",
        "  def __init__(self, path, tokenizer_path, label_to_ind, max_len):\n",
        "    self.encoding = []\n",
        "    self.labels = []\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
        "    self.sep_token_id = self.tokenizer.sep_token_id\n",
        "    self.pad_token_id = self.tokenizer.pad_token_id\n",
        "    self.label_to_ind = label_to_ind\n",
        "    self.max_len = max_len\n",
        "\n",
        "    f = open(path)\n",
        "    data = json.load(f)\n",
        "    #ans?\n",
        "    ans = map(self.parse_doc,data)\n",
        "    text_labels = list(ans)\n",
        "    #labels, text, id\n",
        "    self.text = [x[1] for x in text_labels]\n",
        "    self.labels = [x[0] for x in text_labels]\n",
        "    self.id = [x[2] for x in text_labels]\n",
        "    self.text, self.labels, self.id = zip(*list(filter(lambda x: (len(x[0]) > 0 and len(x[1]) > 0), zip(self.text, self.labels,self.id))))\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.labels)\n",
        "\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    return (self.text[item], self.labels[item], self.id[item])\n",
        "  \n",
        "  def parse_doc(self,x):\n",
        "    doc_labels, text = [],[]\n",
        "    id = x['id']\n",
        "    sentences = x['annotations'][0]['result']\n",
        "    for sentence in sentences:\n",
        "        #doc_labels.append(sentence['value']['labels'][0])\n",
        "        doc_labels.append(self.label_to_ind[sentence['value']['labels'][0]])\n",
        "        #text.append(sentence['value']['text'])\n",
        "        text.append(self.tokenizer.encode(sentence['value']['text'])[:self.max_len])\n",
        "    return (doc_labels, text, id)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iMLh8TqUkWVR"
      },
      "outputs": [],
      "source": [
        "from allennlp.data.dataset_readers.dataset_utils import enumerate_spans\n",
        "import torch\n",
        "\n",
        "class MyCollate:\n",
        "    def __init__(self, pad_idx, sep_idx, max_width, label_to_ind):\n",
        "        self.pad_token_id = pad_idx\n",
        "        #sep token ???\n",
        "        self.sep_token_id = sep_idx\n",
        "        self.max_width = max_width\n",
        "        self.label_to_ind = label_to_ind\n",
        "\n",
        "    def pad_sentence_for_batch(self, tokens_lists, max_len: int):\n",
        "        pad_id = self.pad_token_id\n",
        "        toks_ids = []\n",
        "        att_masks = []\n",
        "        #pad each token in token list\n",
        "        #att mask = 1 * token len\n",
        "        for item_toks in tokens_lists:\n",
        "            padded_item_toks = item_toks + [pad_id] * (max_len - len(item_toks))\n",
        "            toks_ids.append(padded_item_toks)\n",
        "\n",
        "            att_mask = [1] * len(item_toks) + [0] * (max_len - len(item_toks))\n",
        "            att_masks.append(att_mask)\n",
        "            \n",
        "        return toks_ids, att_masks\n",
        "    \n",
        "    def pad_doc_for_batch(self, doc_lengths, labels, segment_ids, max_len):\n",
        "        lab_masks = []\n",
        "        sent_masks = []\n",
        "        seg_masks = []\n",
        "        for i  in range(len(labels)):\n",
        "          lab_item = labels[i] + [self.label_to_ind['MASK']]*(max_len - len(labels[i]))\n",
        "          lab_masks.append(lab_item)\n",
        "\n",
        "          seg_item = segment_ids[i] + [0]*(max_len - len(segment_ids[i]))\n",
        "          seg_masks.append(seg_item)\n",
        "\n",
        "          each_sent_mask = [1] * doc_lengths[i] + [0] * (max_len- doc_lengths[i])\n",
        "          sent_masks.append(each_sent_mask)\n",
        "\n",
        "        return sent_masks, lab_masks, seg_masks\n",
        "\n",
        "    def span_enumeration(self, sent_masks, max_width):\n",
        "        all_span_ids = []\n",
        "        for each in range(len(sent_masks)):\n",
        "            each_span_ids = enumerate_spans(sent_masks[each][(sent_masks[each].nonzero())], offset=0, max_span_width=max_width)\n",
        "            #each_span_ids = enumerate_spans(x[\"sentence_mask\"][each], offset=0, max_span_width=3)\n",
        "            all_span_ids.append(each_span_ids)\n",
        "\n",
        "        max_span_len = max([len(x) for x in all_span_ids])\n",
        "        span_ids = [x+[[0,0]]*(max_span_len-len(x)) for x in all_span_ids]\n",
        "        return span_ids\n",
        "    \n",
        "    \n",
        "    def seg_mask_fix(self,seg_inds):\n",
        "        max_path = self.max_width\n",
        "        counter = np.zeros((len(seg_inds)), dtype=np.int32)\n",
        "        seg_inds_fix = []\n",
        "        for b,  sent_inds in enumerate(seg_inds):\n",
        "            counter = 0\n",
        "            new_inds = []\n",
        "            for i , flag in enumerate(sent_inds):\n",
        "                path_flag = (counter >= max_path-1)\n",
        "                    \n",
        "                mask_step = flag | path_flag\n",
        "                new_inds.append(mask_step)\n",
        "                counter = counter + 1\n",
        "                counter = (1- mask_step)*counter*(counter < max_path)\n",
        "                \n",
        "            seg_inds_fix.append(new_inds)     \n",
        "        return seg_inds_fix\n",
        "\n",
        "    \n",
        "    def convert_labels_to_segments(self,labels):\n",
        "      seg_ids = []\n",
        "      for i  in range(len(labels)):\n",
        "          each_seg_id = []\n",
        "          prev = labels[i][0]\n",
        "          each_seg_id.append(0)\n",
        "          for j in range(1,len(labels[i])):\n",
        "              if(prev != labels[i][j]):\n",
        "                  each_seg_id[len(each_seg_id)-1] = 1\n",
        "                  each_seg_id.append(0)\n",
        "                  prev = labels[i][j]\n",
        "              else:\n",
        "                  each_seg_id.append(0)\n",
        "          each_seg_id[len(each_seg_id)-1] = 1\n",
        "          seg_ids.append(each_seg_id)\n",
        "      segments = self.seg_mask_fix(seg_ids)\n",
        "      return segments\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        batch = filter(lambda x: x is not None, batch)\n",
        "        docs , labels, id = list(zip(*batch))\n",
        "        doc_lengths = [len(x) for x in docs]\n",
        "        sent_lengths = []\n",
        "        for element in docs:\n",
        "          sent_lengths.append([len(i) for i in element])\n",
        "        \n",
        "        batch_sz = len(id)\n",
        "        batch_max_doc_length = max(doc_lengths)\n",
        "        batch_max_sent_length = max([max(sl) for sl in sent_lengths])\n",
        "\n",
        "        docs_tensor = torch.zeros((batch_sz, batch_max_doc_length, batch_max_sent_length), dtype=torch.long)\n",
        "        att_mask = torch.zeros((batch_sz, batch_max_doc_length, batch_max_sent_length), dtype=torch.long)\n",
        "\n",
        "        segments = self.convert_labels_to_segments(labels)\n",
        "        padded_sent_mask, padded_label_id, padded_segments = self.pad_doc_for_batch(doc_lengths, labels, segments, batch_max_doc_length)\n",
        "\n",
        "        label_ids = torch.tensor(padded_label_id , dtype=torch.long)\n",
        "        segment_ids = torch.tensor(padded_segments , dtype=torch.long)\n",
        "        sent_mask = torch.tensor(padded_sent_mask, dtype=torch.long)\n",
        "\n",
        "        spans = torch.tensor(self.span_enumeration(sent_mask, self.max_width), dtype = torch.long)\n",
        "\n",
        "        for doc_idx, doc in enumerate(docs):\n",
        "            padded_token_lists, att_mask_lists = self.pad_sentence_for_batch(doc, batch_max_sent_length)\n",
        "\n",
        "            for sent_idx, (padded_tokens, att_masks) in enumerate(\n",
        "                    zip(padded_token_lists, att_mask_lists)):\n",
        "                docs_tensor[doc_idx, sent_idx, :] = torch.tensor(padded_tokens, dtype=torch.long)\n",
        "                att_mask[doc_idx, sent_idx, :] = torch.tensor(att_masks, dtype=torch.long)\n",
        "        \n",
        "\n",
        "        output = {\n",
        "            \"sentence_mask\": torch.tensor(sent_mask),\n",
        "            \"input_ids\": torch.tensor(docs_tensor),\n",
        "            \"attention_mask\": torch.tensor(att_mask),\n",
        "            \"label_ids\": torch.tensor(label_ids),\n",
        "            \"segment_mask\": torch.tensor(segment_ids),\n",
        "            \"span_indices\": torch.tensor(spans),\n",
        "            \"doc_name\": id\n",
        "        }\n",
        "        return output\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162,
          "referenced_widgets": [
            "674889cd6cf34a7fa258e8420a2d1f37",
            "c4f4e842d8b14f62b1733d4dc89277ea",
            "88699d07a5174e41ba6bfa0ee75f8ac7",
            "cfab0efd04824078b75c96c55076161f",
            "fba628e888bb485cbf54f1bd5283a4be",
            "64c8f3ca1b0f449dabb520b93027ddf1",
            "7cf7e2a774044bfd886effd679486b10",
            "df14c414329c40d7a3736fbf8d6a03e2",
            "53ab88f470d54bd5adbf3f9f4bec13d1",
            "d639947914e84548b8b4bf8eb0ef3c5d",
            "b73335e747ce4270b4986d592169932f",
            "13c2b694dc4941afaf235b58f20aa85f",
            "18f1695e3eda42d58f2ecdd0c3ab9426",
            "c6eb73c1e7444f6083b441ffe3400e12",
            "8f9005acf79243a189fcfbe2b1eac624",
            "98fe32532a304a8282add6b25c52d1c7",
            "f874b0d9b25744479398d7cfafcc12c7",
            "e3e47c039f4b4804a6276a7d0d08feaf",
            "c9c7e1fdf45b4defa924d71274ab1d3a",
            "ed79e8dda8484edda93cdb368fff3949",
            "2a90ab1229dc45f888a2975f298fe7e0",
            "bbb4d83a7d9e4d41b7ab47fae0e5ea83",
            "99660b96a3c641ab8b1f318763a67c8e",
            "15acdcb1cc094ff6963cf2f0a16eacc1",
            "7c1dc6d4c0d74929aa92e8608095dd0d",
            "3509bd32bfc149c5a1463668a8cd44ab",
            "51b0e2f45a8d4e3eab815aa402883962",
            "de1b76926b6748189defe4746d2f8c6f",
            "891b5b5ba0124b3f935b01c2f29adb8e",
            "0b9e4c39c525435a94c7884d74877403",
            "3c497772474e4a87b61af44d840c8d33",
            "6f143abfb81a4a45b377bd1d93b7c52b",
            "c64cc81f9cc34392bfe3c0867abb0d34",
            "36794b1c84fd476db7314087a16466c0",
            "1876d10c710f4568ab0878d384bd3b3d",
            "e8c22a2edae6401da6d385d9e908b793",
            "e0bdbe69ba55494fa8cb6e5e51f12785",
            "41d2e3d7dca64f4a8c5c8250168d6c2a",
            "2e3388cc950f40e4aa5c45dbeeab8c33",
            "27569f0920204db693743a7dd7334fc4",
            "fb940d745a404485871911c35b7136ba",
            "9a860322edaa4d0f8cb0092f1e44cf92",
            "b731b848ded444ffa79b23fbcc2bdc1d",
            "12fed375ae214b879e919e41ccd4cf33"
          ]
        },
        "id": "mUq6uHx-QjFP",
        "outputId": "69969dc3-e0fe-448b-abe6-5c5d26a01ba9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Legal DS/Pubmed\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "674889cd6cf34a7fa258e8420a2d1f37",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13c2b694dc4941afaf235b58f20aa85f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99660b96a3c641ab8b1f318763a67c8e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36794b1c84fd476db7314087a16466c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# LABELS = [\"MASK\",\"PREAMBLE\", \"NONE\", \"FAC\", \"ISSUE\", \"ARG_RESPONDENT\", \"ARG_PETITIONER\", \"ANALYSIS\", \"PRE_RELIED\",\n",
        "#               \"PRE_NOT_RELIED\", \"STA\", \"RLC\", \"RPC\", \"RATIO\"]\n",
        "\n",
        "# LABELS = [\"DEFAULT\", 'MASK', \"NONE\", \"Facts\", \"Argument\", \"Ratio of the decision\", \"Statute\", \"Precedent\", \"Ruling by Present Court\", \"Ruling by Lower Court\"]\n",
        "\n",
        "LABELS = ['MASK', 'OBJECTIVE', 'BACKGROUND', 'METHODS', 'RESULTS', 'CONCLUSIONS']\n",
        "\n",
        "%cd /content/drive/My\\ Drive/Legal\\ DS/Pubmed/\n",
        "\n",
        "\n",
        "labels_int = range(len(LABELS)) \n",
        "label_to_ind = dict( zip(LABELS,labels_int))\n",
        "#label_to_ind['MASK'] = len(label_to_ind)\n",
        "label_to_ind['START'] = len(label_to_ind)\n",
        "label_to_ind['STOP'] = len(label_to_ind)\n",
        "\n",
        "bert_model = \"bert-base-uncased\"\n",
        "#bert_model = \"zlucia/custom-legalbert\"\n",
        "\n",
        "train_dataset = RRDataset('sample_train_to_ekstep.json',tokenizer_path = bert_model, label_to_ind = label_to_ind, max_len = 128)\n",
        "dev_dataset = RRDataset('sample_dev_to_ekstep.json',tokenizer_path = bert_model, label_to_ind = label_to_ind, max_len = 128)\n",
        "#dev_dataset = RRDataset('dev.json',tokenizer_path = bert_model, label_to_ind = label_to_ind, max_len = 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUqat4U-foU8",
        "outputId": "24d126cd-927e-44fd-8c21-984118424754"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5, 3)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_dataset), len(dev_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fujhATAWk_Wl"
      },
      "outputs": [],
      "source": [
        "#max_width = max span length\n",
        "#batch_size default 1\n",
        "\n",
        "train_dataloader =  DataLoader(train_dataset, batch_size=1, shuffle=True, collate_fn = MyCollate(pad_idx = train_dataset.pad_token_id, sep_idx = train_dataset.pad_token_id, max_width = 3, label_to_ind=label_to_ind))\n",
        "\n",
        "dev_dataloader =  DataLoader(dev_dataset, batch_size=1, shuffle=True, collate_fn = MyCollate(pad_idx = train_dataset.pad_token_id, sep_idx = train_dataset.pad_token_id, max_width = 3, label_to_ind=label_to_ind))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "92e5cc5aa19f4c368aaa48e844751932",
            "9c1f102b475e4ebeae72a5959444b295",
            "eb7010c4f9e044868a9b6bf560edb733",
            "c950d5c21ecd4c5db09d7eeb23a00d37",
            "e24b0f412eec41a490bc1fea71ac2ea8",
            "2f772cb95b4b49a18f1c2379d1aed87c",
            "4024b058295140e682ea95b872faddff",
            "47567b7609aa48078c0a5bf9698a9329",
            "38dbeaa7298a492c9a9f5648ea60f805",
            "263dda38a56b4073ac4ec6b45336638e",
            "ce33d78ec6a24a2ea60c8a29e505bf42"
          ]
        },
        "id": "hiMHwONyljQi",
        "outputId": "3ee27ece-0477-446b-9c15-19b2eefadb95"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92e5cc5aa19f4c368aaa48e844751932",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 17]) torch.Size([1, 17, 66]) torch.Size([1, 17, 66]) torch.Size([1, 17]) ('###24633056\\n',) torch.Size([1, 48, 2]) torch.Size([1, 17])\n",
            "tensor([[1, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 2, 2, 2, 2]])\n",
            "tensor([[1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1]])\n"
          ]
        }
      ],
      "source": [
        "for batch_idx, x in tqdm(enumerate(train_dataloader),total=len(train_dataloader), leave=False):\n",
        "      #print(x[\"sentence_mask\"], x[\"input_ids\"],x[\"attention_mask\"], x[\"label_ids\"])\n",
        "      print(x[\"sentence_mask\"].shape, x[\"input_ids\"].shape,x[\"attention_mask\"].shape, x[\"label_ids\"].shape, x[\"doc_name\"],x[\"span_indices\"].shape,x[\"segment_mask\"].shape)\n",
        "      #print(x['span_indices'])\n",
        "      print(x['label_ids'])\n",
        "      print(x[\"segment_mask\"])\n",
        "      break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "BJ0vvGKFHCo4",
        "outputId": "14a9ae1c-f9fb-4d02-ba09-dd9f82369db8"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-32006cf62138>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspan_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'doc_labels' is not defined"
          ]
        }
      ],
      "source": [
        "print(doc_labels[0])\n",
        "print(span_labels[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GjoUAB9FD4Dj"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "class SpanCRF(nn.Module):\n",
        "    def __init__(self,  label_to_ind, max_path):\n",
        "        super(SpanCRF, self).__init__()\n",
        "\n",
        "        self.tag_to_ix = label_to_ind\n",
        "        self.tagset_size = len(self.tag_to_ix)\n",
        "        self.max_path = max_path\n",
        "        \n",
        "        self.transitions = nn.Parameter(torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "\n",
        "        \n",
        "    def _forward_alg(self, logits, len_list, is_volatile=False):\n",
        "        \"\"\"\n",
        "        Computes the (batch_size,) denominator term (FloatTensor list) for the log-likelihood, which is the\n",
        "        sum of the likelihoods across all possible state sequences.\n",
        "        \n",
        "        Arguments:\n",
        "            logits: [batch_size, seq_len, max_path, n_labels] FloatTensor\n",
        "            lens: [batch_size] LongTensor\n",
        "        \"\"\"\n",
        "        batch_size, seq_len, max_path, n_labels = logits.size()\n",
        "        \n",
        "        alpha = logits.data.new(batch_size, seq_len+1, self.tagset_size).fill_(-10000).to(device)\n",
        "        alpha[:, 0, self.tag_to_ix['START']] = 0\n",
        "        alpha = Variable(alpha, volatile=is_volatile)\n",
        "        \n",
        "        # Transpose batch size and time dimensions:\n",
        "        logits_t = logits.permute(1,0,2,3).to(device)\n",
        "        c_lens = len_list.clone()\n",
        "        \n",
        "        alpha_out_sum = Variable(logits.data.new(batch_size,max_path, self.tagset_size).fill_(0)).to(device)\n",
        "        mat = Variable(logits.data.new(batch_size,self.tagset_size,self.tagset_size).fill_(0)).to(device)\n",
        "        \n",
        "        for j, logit in enumerate(logits_t):\n",
        "            for i in range(0,max_path):\n",
        "                if i<=j:\n",
        "                    alpha_exp = alpha[:,j-i, :].clone().unsqueeze(1).expand(batch_size,self.tagset_size, self.tagset_size)\n",
        "                    logit_exp = logit[:, i].unsqueeze(-1).expand(batch_size, self.tagset_size, self.tagset_size).to(device)\n",
        "                    trans_exp = self.transitions.unsqueeze(0).expand_as(alpha_exp)\n",
        "                    mat = alpha_exp + logit_exp + trans_exp\n",
        "                    alpha_out_sum[:,i,:] =  self.log_sum_exp(mat , 2, keepdim=True).squeeze(2)\n",
        "\n",
        "            alpha_nxt = self.log_sum_exp(alpha_out_sum , dim=1, keepdim=True).squeeze(1)\n",
        "            \n",
        "            mask = Variable((c_lens > 0).float().unsqueeze(-1).expand(batch_size,self.tagset_size)).to(device)\n",
        "            alpha_nxt = mask * alpha_nxt + (1 - mask) *alpha[:, j, :].clone() \n",
        "            \n",
        "            c_lens = c_lens - 1      \n",
        "\n",
        "            alpha[:,j+1, :] = alpha_nxt\n",
        "\n",
        "        alpha[:,-1,:] = alpha[:,-1,:] + self.transitions[self.tag_to_ix['STOP']].unsqueeze(0).expand_as(alpha[:,-1,:])\n",
        "        norm = self.log_sum_exp(alpha[:,-1,:], 1).squeeze(-1)\n",
        "\n",
        "        return norm\n",
        "\n",
        "        \n",
        "    def viterbi_decode(self, logits, lens):\n",
        "        \"\"\"\n",
        "        Use viterbi algorithm to compute the most probable path of segments\n",
        "        \n",
        "        Arguments:\n",
        "            logits: [batch_size, seq_len, max_path, n_labels] FloatTensor\n",
        "            lens: [batch_size] LongTensor\n",
        "        \"\"\"\n",
        "        batch_size, seq_len, max_path, n_labels = logits.size()\n",
        "        logits = logits.to(device)\n",
        "        # Transpose to batch size and time dimensions\n",
        "        logits_t = logits.permute(1,0,2,3)\n",
        "        \n",
        "        vit = Variable(logits.data.new(batch_size,seq_len+1, self.tagset_size).fill_(-10000),\n",
        "                                       volatile = not self.training).to(device)\n",
        "        \n",
        "        vit_tag_max = Variable(logits.data.new(batch_size,max_path, self.tagset_size).fill_(-10000),\n",
        "                                   volatile = not self.training).to(device)\n",
        "        \n",
        "        vit_tag_argmax = Variable(logits.data.new(batch_size,max_path, self.tagset_size).fill_(-100),\n",
        "                                   volatile = not self.training).to(device)\n",
        "        vit[:,0, self.tag_to_ix['START']] = 0\n",
        "        c_lens = Variable(lens.clone(), volatile= not self.training).to(device)\n",
        "        \n",
        "        pointers = Variable(logits.data.new(batch_size, seq_len, self.tagset_size, 2 ).fill_(-100))\n",
        "        for j, logit in enumerate(logits_t):\n",
        "            for i in range(0,max_path):\n",
        "                if i<=j:\n",
        "                    vit_exp = vit[:,j-i, :].clone().unsqueeze(1).expand(batch_size,self.tagset_size, self.tagset_size)\n",
        "                    trn_exp = self.transitions.unsqueeze(0).expand_as(vit_exp)\n",
        "                    vit_trn_sum = vit_exp + trn_exp\n",
        "                    vt_max, vt_argmax = vit_trn_sum.max(2)\n",
        "                    vit_nxt = vt_max + logit[:, i]\n",
        "                    vit_tag_max[:,i,:] = vit_nxt\n",
        "                    vit_tag_argmax[:,i,:] = vt_argmax\n",
        "           \n",
        "            seg_vt_max, seg_vt_argmax = vit_tag_max.max(1)\n",
        "            \n",
        "            mask = (c_lens > 0).float().unsqueeze(-1).expand_as(seg_vt_max)\n",
        "            vit[:, j+1, :] = mask*seg_vt_max + (1-mask)*vit[:, j, :].clone()\n",
        "            \n",
        "            mask = (c_lens == 1).float().unsqueeze(-1).expand_as(  vit[:, j+1, :])\n",
        "            vit[:, j+1, :] = vit[:, j+1, :] +  mask * self.transitions[ self.tag_to_ix['STOP'] ].unsqueeze(0).expand_as( vit[:, j+1, :] )\n",
        "            \n",
        "            idx_exp = seg_vt_argmax.unsqueeze(1)\n",
        "            pointers[:,j,:,0] =  torch.gather(vit_tag_argmax, 1,idx_exp ).squeeze(1)\n",
        "            pointers[:,j,:,1] = seg_vt_argmax \n",
        "            \n",
        "            c_lens = c_lens - 1  \n",
        "        \n",
        "        #Get the argmax from the last viterbi scores and follow the reverse pointers for the best path \n",
        "        end_max , end_max_idx = vit[:,-1,:].max(1)\n",
        "        end_max_idx = end_max_idx.data.cpu().numpy()\n",
        "        \n",
        "        pointers = pointers.data.long().cpu().numpy()\n",
        "        pointers_rev = np.flip(pointers,1)\n",
        "        paths = []\n",
        "        segments = []\n",
        "        \n",
        "        for b in range(batch_size):\n",
        "            #Different lengths each sentence, so get the starting index on the reverse list\n",
        "            start_index = seq_len-lens[b] \n",
        "            path = [end_max_idx[b]]\n",
        "            segment = [lens[b]]\n",
        "            \n",
        "            if (start_index >= seq_len -1):\n",
        "                paths.append(path)\n",
        "                continue\n",
        "            \n",
        "            max_tuple = pointers_rev[b,start_index,end_max_idx[b]]\n",
        "            start_index += 1\n",
        "            prev_tag = end_max_idx[b]\n",
        "            next_tag = max_tuple[0]\n",
        "            next_jump = max_tuple[1]\n",
        "            \n",
        "            for j, argmax in enumerate(pointers_rev[b,start_index:,:]):\n",
        "                #Append same tag as many times as indicated by the best segment length we stored\n",
        "                if next_jump > 0:\n",
        "                    next_jump -= 1\n",
        "                    path.insert(0, prev_tag)\n",
        "                    continue\n",
        "                #Switch to next tag when we hit zero\n",
        "                else:\n",
        "                    segment.insert(0, lens[b]- j-1)\n",
        "                    path.insert(0, next_tag)\n",
        "                \n",
        "                #Get the next tag, and the number of times we have to append the previous one\n",
        "                prev_tag = next_tag\n",
        "                max_tuple = argmax[next_tag]\n",
        "                next_tag = max_tuple[0]\n",
        "                next_jump = max_tuple[1]\n",
        "                \n",
        "            segments.append(segment)     \n",
        "            paths.append(path)\n",
        "            \n",
        "        return paths, segments\n",
        "        \n",
        "        \n",
        "    def _bilstm_score(self, logits, labels, seg_inds, lens):\n",
        "        \n",
        "        \"\"\"\n",
        "        Computes the (batch_size,) numerator (FloatTensor list) for the log-likelihood, which is the\n",
        "        \n",
        "        Arguments:\n",
        "            logits: [batch_size, seq_len, max_path, n_labels] FloatTensor\n",
        "            labels: [batch_size, seq_len] LongTensor\n",
        "            seg_inds: [batch_size, seq_len] LongTensor\n",
        "            lens: [batch_size] LongTensor\n",
        "        \"\"\"\n",
        "        lens = Variable( lens, volatile = not self.training)\n",
        "        \n",
        "        batch_size, max_len, _, _ = logits.size()\n",
        "        \n",
        "        # Transpose to batch size and time dimensions\n",
        "        labels = labels.transpose(1,0)\n",
        "        \n",
        "        seg_inds = seg_inds.transpose(1,0).data.cpu().numpy()\n",
        "        labels_exp = labels.unsqueeze(-1)\n",
        "\n",
        "        #Construct the mask the will sellect the corrects segments from all possible segments for each timstep\n",
        "        mask_seg = np.zeros(( batch_size, max_len, self.max_path))\n",
        "        \n",
        "        mask_step =  np.zeros(( batch_size), dtype=np.int32)\n",
        "        counter = np.zeros((batch_size), dtype=np.int32)\n",
        "        \n",
        "        #For each timstep accross all sentences\n",
        "        for i in range(0,max_len):\n",
        "            #0 or 1 depending if we are on the end of a segment\n",
        "            mask_step =  seg_inds[:, i] \n",
        "            mask_seg[np.arange(batch_size), i, counter] = mask_step \n",
        "            counter = counter + 1\n",
        "            counter = (1- mask_step)*counter*(counter < self.max_path)\n",
        "           \n",
        "        mask_seg = torch.from_numpy(mask_seg).float()\n",
        "        if next(self.parameters()).is_cuda == True:\n",
        "            mask_seg = mask_seg.cuda()\n",
        "            \n",
        "        mask_seg = mask_seg.unsqueeze(-1).expand_as(logits)\n",
        "        mask_seg = Variable(mask_seg,  volatile = not self.training).to(device)\n",
        "        \n",
        "        logit_mask = logits*mask_seg\n",
        "        sum_cols = torch.sum(logit_mask, dim=2).squeeze(2)\n",
        "        \n",
        "        all_scores = torch.gather(sum_cols, 2, labels_exp).squeeze(-1)\n",
        "        \n",
        "        mask_time = self.sequence_mask(lens).float()\n",
        "        all_scores = all_scores*mask_time\n",
        "        \n",
        "        sum_seg_scores = torch.sum(all_scores, dim=1).squeeze(-1)\n",
        "\n",
        "        return  sum_seg_scores\n",
        "        \n",
        "    def score(self, logits, y, seg_inds, lens):\n",
        "        logits = logits.to(device)\n",
        "        bilstm_score = self._bilstm_score(logits, y, seg_inds, lens)\n",
        "        transition_score = self.transition_score(y, lens, seg_inds )\n",
        "        \n",
        "        score = transition_score + bilstm_score\n",
        "\n",
        "        return score\n",
        "    \n",
        "    def transition_score(self, labels, lens, mask_seg_idx):\n",
        "        \"\"\"\n",
        "        Computes the (batch_size,) scores (FloatTensor list) that will be added to the emission scores\n",
        "        \n",
        "        Arguments:\n",
        "            logits: [batch_size, seq_len, max_path, n_labels] FloatTensor\n",
        "            labels: [batch_size, seq_len] LongTensor\n",
        "            seg_inds: [batch_size, seq_len] LongTensor\n",
        "            lens: [batch_size] LongTensor\n",
        "        \"\"\"\n",
        "        lens = Variable( lens, volatile = not self.training)\n",
        "        labels = labels.transpose(1,0)\n",
        "        mask_seg_idx = mask_seg_idx.transpose(1,0)\n",
        "        batch_size, seq_len = labels.size()\n",
        "        # pad labels with <start> and <stop> indices\n",
        "        labels_ext = Variable(labels.data.new(batch_size, seq_len + 2))\n",
        "        labels_ext[:, 0] = self.tag_to_ix['START']\n",
        "        labels_ext[:, 1:-1] = labels\n",
        "        mask = self.sequence_mask(lens + 1, max_len=seq_len + 2).long()\n",
        "        pad_stop = Variable(labels.data.new(1).fill_(self.tag_to_ix['STOP']))\n",
        "        \n",
        "        pad_stop = pad_stop.unsqueeze(-1).expand(batch_size, seq_len + 2)\n",
        "        labels_ext = (1 + (-1)*mask) * pad_stop + mask * labels_ext\n",
        "        trn = self.transitions\n",
        "        \n",
        "        trn_exp = trn.unsqueeze(0).expand(batch_size, *trn.size())\n",
        "        lbl_r = labels_ext[:, 1:]\n",
        "        lbl_rexp = lbl_r.unsqueeze(-1).expand(*lbl_r.size(), trn.size(0))\n",
        "        trn_row = torch.gather(trn_exp, 1, lbl_rexp)\n",
        "        \n",
        "        lbl_lexp = labels_ext[:, :-1].unsqueeze(-1)\n",
        "        trn_scr = torch.gather(trn_row, 2, lbl_lexp)\n",
        "        trn_scr = trn_scr.squeeze(-1)\n",
        "        \n",
        "        # Mask sentences in time dim\n",
        "        mask = self.sequence_mask(lens + 1).float()\n",
        "        trn_scr = trn_scr * mask\n",
        "        \n",
        "        trn_scr[:, 1:] = trn_scr[:, 1:].clone()*mask_seg_idx.float() \n",
        "        \n",
        "        score = trn_scr.sum(1).squeeze(-1)\n",
        "        \n",
        "        return score\n",
        "\n",
        "    def loglik(self, logits, y, lens):\n",
        "        norm_score = self._forward_alg(logits, lens)\n",
        "        sequence_score = self.score(logits, y, lens, logits=logits)\n",
        "        loglik = sequence_score - norm_score\n",
        "\n",
        "        return loglik   \n",
        "\n",
        "\n",
        "    def log_sum_exp(self,vec, dim=0, keepdim=True):\n",
        "        max_val, idx = torch.max(vec, dim, keepdim=True)\n",
        "        max_exp = max_val.expand_as(vec)\n",
        "    \n",
        "        return max_val + torch.log(torch.sum(torch.exp(vec - max_exp), dim, keepdim=keepdim))\n",
        "\n",
        "    \n",
        "    def sequence_mask(self,lens, max_len=None):\n",
        "        batch_size = lens.size(0)\n",
        "        if max_len is None:\n",
        "        \n",
        "            max_len = lens.max().data\n",
        "            \n",
        "        ranges = torch.arange(0, max_len).long()\n",
        "        ranges = ranges.unsqueeze(0).expand(batch_size, max_len)\n",
        "        ranges = Variable(ranges)\n",
        "        if lens.data.is_cuda:\n",
        "            ranges = ranges.cuda()\n",
        "\n",
        "        lens_exp = lens.unsqueeze(1).expand_as(ranges)\n",
        "        mask = ranges < lens_exp\n",
        "        return mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hCrxoxXjHJbx"
      },
      "outputs": [],
      "source": [
        "from allennlp.common.util import pad_sequence_to_length\n",
        "from allennlp.modules.seq2seq_encoders import PytorchSeq2SeqWrapper\n",
        "from allennlp.nn.util import masked_mean, masked_softmax\n",
        "from allennlp.modules.span_extractors import EndpointSpanExtractor,SelfAttentiveSpanExtractor\n",
        "import copy\n",
        "\n",
        "from transformers import BertModel\n",
        "\n",
        "from allennlp.modules import ConditionalRandomField\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class CRFOutputLayer(torch.nn.Module):\n",
        "    ''' CRF output layer consisting of a linear layer and a CRF. '''\n",
        "    def __init__(self, in_dim, num_labels):\n",
        "        super(CRFOutputLayer, self).__init__()\n",
        "        self.num_labels = num_labels\n",
        "        self.classifier = torch.nn.Linear(in_dim, self.num_labels)\n",
        "        self.crf = ConditionalRandomField(self.num_labels)\n",
        "\n",
        "    def forward(self, x, mask, labels=None):\n",
        "        ''' x: shape: batch, max_sequence, in_dim\n",
        "            mask: shape: batch, max_sequence\n",
        "            labels: shape: batch, max_sequence\n",
        "        '''\n",
        "\n",
        "        batch_size, max_sequence, in_dim = x.shape\n",
        "\n",
        "        logits = self.classifier(x)\n",
        "        outputs = {}\n",
        "        if labels is not None:\n",
        "            log_likelihood = self.crf(logits, labels, mask)\n",
        "            loss = -log_likelihood\n",
        "            outputs[\"loss\"] = loss\n",
        "        else:\n",
        "            best_paths = self.crf.viterbi_tags(logits, mask)\n",
        "            predicted_label = [x for x, y in best_paths]\n",
        "            predicted_label = [pad_sequence_to_length(x, desired_length=max_sequence) for x in predicted_label]\n",
        "            predicted_label = torch.tensor(predicted_label)\n",
        "            outputs[\"predicted_label\"] = predicted_label\n",
        "\n",
        "            #log_denominator = self.crf._input_likelihood(logits, mask)\n",
        "            #log_numerator = self.crf._joint_likelihood(logits, predicted_label, mask)\n",
        "            #log_likelihood = log_numerator - log_denominator\n",
        "            #outputs[\"log_likelihood\"] = log_likelihood\n",
        "\n",
        "        return outputs\n",
        "        \n",
        "\n",
        "\n",
        "class AttentionPooling(torch.nn.Module):\n",
        "    def __init__(self, in_features, dimension_context_vector_u=200, number_context_vectors=5):\n",
        "        super(AttentionPooling, self).__init__()\n",
        "        self.dimension_context_vector_u = dimension_context_vector_u\n",
        "        self.number_context_vectors = number_context_vectors\n",
        "        self.linear1 = torch.nn.Linear(in_features=in_features, out_features=self.dimension_context_vector_u, bias=True)\n",
        "        self.linear2 = torch.nn.Linear(in_features=self.dimension_context_vector_u,\n",
        "                                       out_features=self.number_context_vectors, bias=False)\n",
        "\n",
        "        self.output_dim = self.number_context_vectors * in_features\n",
        "\n",
        "    def forward(self, tokens, mask):\n",
        "        #shape tokens: (batch_size, tokens, in_features)\n",
        "\n",
        "        # compute the weights\n",
        "        # shape tokens: (batch_size, tokens, dimension_context_vector_u)\n",
        "        a = self.linear1(tokens)\n",
        "        a = torch.tanh(a)\n",
        "        # shape (batch_size, tokens, number_context_vectors)\n",
        "        a = self.linear2(a)\n",
        "        # shape (batch_size, number_context_vectors, tokens)\n",
        "        a = a.transpose(1, 2)\n",
        "        a = masked_softmax(a, mask)\n",
        "\n",
        "        # calculate weighted sum\n",
        "        s = torch.bmm(a, tokens)\n",
        "        s = s.view(tokens.shape[0], -1)\n",
        "        return s\n",
        "\n",
        "\n",
        "\n",
        "class BertTokenEmbedder(torch.nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertTokenEmbedder, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(config[\"bert_model\"])\n",
        "        self.bert_trainable = config[\"bert_trainable\"]\n",
        "        self.bert_hidden_size = self.bert.config.hidden_size\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = self.bert_trainable\n",
        "\n",
        "    def forward(self, batch):\n",
        "        if \"bert_embeddings\" in batch:\n",
        "            return batch[\"bert_embeddings\"]\n",
        "\n",
        "        documents, sentences, tokens = batch[\"input_ids\"].shape\n",
        "        attention_mask = batch[\"attention_mask\"].view(-1, tokens)\n",
        "        input_ids = batch[\"input_ids\"].view(-1, tokens)\n",
        "\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        # shape (documents*sentences, tokens, 768)\n",
        "        bert_embeddings = outputs[0]\n",
        "\n",
        "        if not self.bert_trainable:\n",
        "            batch[\"bert_embeddings\"] = bert_embeddings.to(\"cpu\")\n",
        "        return bert_embeddings\n",
        "\n",
        "class BertHSLN(torch.nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertHSLN, self).__init__()\n",
        "\n",
        "        self.bert = BertTokenEmbedder(config)\n",
        "        self.dropout = torch.nn.Dropout(config[\"dropout\"])\n",
        "        self.word_lstm_hidden_size = config[\"word_lstm_hs\"]\n",
        "        self.word_lstm = PytorchSeq2SeqWrapper(torch.nn.LSTM(input_size=self.bert.bert_hidden_size,\n",
        "                                  hidden_size=self.word_lstm_hidden_size,\n",
        "                                  num_layers=1, batch_first=True, bidirectional=True))\n",
        "\n",
        "        self.attention_pooling = AttentionPooling(2 * self.word_lstm_hidden_size,\n",
        "                                                  dimension_context_vector_u=config[\"att_pooling_dim_ctx\"],\n",
        "                                                  number_context_vectors=config[\"att_pooling_num_ctx\"])\n",
        "        \n",
        "        input_dim = self.attention_pooling.output_dim\n",
        "        self.sentence_lstm_hidden_size = config[\"sentence_lstm_hs\"]\n",
        "        self.sentence_lstm = PytorchSeq2SeqWrapper(torch.nn.LSTM(input_size=input_dim,\n",
        "                                  hidden_size=self.sentence_lstm_hidden_size,\n",
        "                                  num_layers=1, batch_first=True, bidirectional=True))\n",
        "        \n",
        "\n",
        "\n",
        "        self.input_dim = self.sentence_lstm_hidden_size * 2\n",
        "        self.max_path = config[\"max_path\"]\n",
        "        self.num_labels = len(config['label_to_ind'])\n",
        "        \n",
        "        self.span_crf = config[\"span_crf\"]\n",
        "        self.crf = config[\"crf\"]\n",
        "\n",
        "        if self.crf:\n",
        "          self.crf_fc = nn.Linear(self.input_dim, self.num_labels)\n",
        "          self.crf = SpanCRF(config[\"label_to_ind\"],1)\n",
        "          #self.crf = CRFOutputLayer(in_dim=self.input_dim, num_labels=self.num_labels)\n",
        "\n",
        "        if self.span_crf:\n",
        "          #self.endpoint_span_extractor = EndpointSpanExtractor(self.sentence_lstm_hidden_size * 2,\n",
        "          #                                                    combination=\"x,y,x*y,x-y\",\n",
        "          #                                                    num_width_embeddings=config[\"max_path\"],\n",
        "          #                                                    span_width_embedding_dim=config[\"span_width_embedding_dim\"],\n",
        "          #                                                    bucket_widths=True)\n",
        "          self.endpoint_span_extractor = SelfAttentiveSpanExtractor(self.sentence_lstm_hidden_size * 2,\n",
        "                                                              num_width_embeddings=config[\"max_path\"],\n",
        "                                                              span_width_embedding_dim=config[\"span_width_embedding_dim\"],\n",
        "                                                              bucket_widths=True)\n",
        "          #self.span_input_dim = self.sentence_lstm_hidden_size * 2 * 4 + config[\"span_width_embedding_dim\"]\n",
        "          self.span_input_dim = self.sentence_lstm_hidden_size * 2  + config[\"span_width_embedding_dim\"]\n",
        "          \n",
        "          self.crf_spanfc = nn.Linear(self.span_input_dim, self.num_labels)\n",
        "          self.spancrf = SpanCRF(config[\"label_to_ind\"],self.max_path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, batch, labels=None, eval=False):\n",
        "\n",
        "        documents, sentences, tokens = batch[\"input_ids\"].shape\n",
        "  \n",
        "        # shape (documents*sentences, tokens, 768)\n",
        "        bert_embeddings = self.bert(batch)\n",
        "        bert_embeddings = self.dropout(bert_embeddings)\n",
        "\n",
        "        tokens_mask = batch[\"attention_mask\"].view(-1, tokens)\n",
        "\n",
        "        # shape (documents*sentences, tokens, 2*lstm_hidden_size)\n",
        "        bert_embeddings_encoded = self.word_lstm(bert_embeddings, tokens_mask)\n",
        "\n",
        "        #shape (documents*sentences, pooling_out)\n",
        "        sentence_embeddings = self.attention_pooling(bert_embeddings_encoded, tokens_mask)\n",
        "\n",
        "        # shape: (documents, sentences, pooling_out)\n",
        "        sentence_embeddings = sentence_embeddings.view(documents, sentences, -1)\n",
        "        sentence_embeddings = self.dropout(sentence_embeddings)\n",
        "\n",
        "\n",
        "        sentence_mask = batch[\"sentence_mask\"]\n",
        "\n",
        "        # shape: (documents, sentence, 2*lstm_hidden_size)\n",
        "        sentence_embeddings_encoded = self.sentence_lstm(sentence_embeddings, sentence_mask)\n",
        "        sentence_embeddings_encoded = self.dropout(sentence_embeddings_encoded)\n",
        "\n",
        "        sentence_len = torch.sum(sentence_mask,dim=-1)\n",
        "        output = {}\n",
        "\n",
        "        if self.span_crf:\n",
        "            span_embeddings = self.endpoint_span_extractor(sentence_embeddings_encoded,batch[\"span_indices\"], sentence_mask)\n",
        "            segment_rep = self.crf_spanfc(span_embeddings)\n",
        "            _,max_span_len,_ = segment_rep.shape\n",
        "        \n",
        "            segment_span_feat = torch.zeros(documents, sentences, self.max_path, self.num_labels)\n",
        "\n",
        "        \n",
        "            batch_size, max_span_len,_ = batch[\"span_indices\"].shape\n",
        "            _, max_seq_len, max_path_len, _ = segment_span_feat.shape\n",
        "\n",
        "            for i in range(batch_size):\n",
        "              for j in range(max_span_len):\n",
        "                start_idx = batch[\"span_indices\"][i][j][0]\n",
        "                len_idx = batch[\"span_indices\"][i][j][1] - batch[\"span_indices\"][i][j][0]\n",
        "                segment_span_feat[i,start_idx,len_idx,:] = segment_rep[i][j]\n",
        "            \n",
        "            segment_mask = batch[\"segment_mask\"]\n",
        "            \n",
        "            if not eval:\n",
        "                span_forward_var_batch = self.spancrf._forward_alg(segment_span_feat,sentence_len )\n",
        "                span_gold_score_batch = self.spancrf.score(segment_span_feat, labels.transpose(0,1) , segment_mask.transpose(0,1),sentence_len)\n",
        "                loss = (span_forward_var_batch-span_gold_score_batch).mean()\n",
        "                #output['span_crf'] = {\"forward_var_batch\":span_forward_var_batch , \"gold_score_batch\" : span_gold_score_batch}\n",
        "                output['loss2'] = loss\n",
        "\n",
        "        if self.crf:\n",
        "            #output = self.crf(sentence_embeddings_encoded, sentence_mask, labels)\n",
        "            #return output \n",
        "\n",
        "            segment_feat = sentence_embeddings_encoded.unsqueeze(2)\n",
        "            segment_feat = self.crf_fc(segment_feat)\n",
        "            segment_feat = segment_feat.view(documents, sentences, 1, self.num_labels)\n",
        "            \n",
        "            if not eval:\n",
        "                forward_var_batch = self.crf._forward_alg(segment_feat,sentence_len )\n",
        "                gold_score_batch = self.crf.score(segment_feat, labels.transpose(0,1) , sentence_mask.transpose(0,1),sentence_len)\n",
        "                loss = (forward_var_batch-gold_score_batch  ).mean()\n",
        "                output['loss1'] = loss\n",
        "            \n",
        "\n",
        "        if eval:\n",
        "            if self.crf:\n",
        "              crf_tag_seqs, crf_segments = self.crf.viterbi_decode(segment_feat,sentence_len )\n",
        "              #output['crf'] = {\"tag_seqs\":crf_tag_seqs, \"segments\":  crf_segments }\n",
        "              output[\"predicted_label1\"] = crf_tag_seqs\n",
        "            if self.span_crf:\n",
        "              span_crf_tag_seqs, span_crf_segments = self.spancrf.viterbi_decode(segment_span_feat,sentence_len )\n",
        "              #output['span_crf'] = {\"tag_seqs\":span_crf_tag_seqs, \"segments\":  span_crf_segments }\n",
        "              output[\"predicted_label2\"] = span_crf_tag_seqs\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "S_kWu8asfteX"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"dropout\":0.5,\n",
        "    \"word_lstm_hs\":758,\n",
        "    \"att_pooling_dim_ctx\":200,\n",
        "    \"att_pooling_num_ctx\": 15,\n",
        "    \"sentence_lstm_hs\":758,\n",
        "    \"bert_model\": bert_model,\n",
        "    \"bert_trainable\": False,\n",
        "    \"label_to_ind\" : label_to_ind,\n",
        "    \"max_path\": 10,\n",
        "    \"span_width_embedding_dim\" :100,\n",
        "    \"lr_epoch_decay\":0.9,\n",
        "    \"crf\": False,\n",
        "    \"span_crf\" : True\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "PH6iJd1GJocl"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support, classification_report, confusion_matrix, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "def eval_model(model, eval_batches, device,label_to_ind, id):\n",
        "    model.eval()\n",
        "    true_labels = []\n",
        "    labels_dict={}\n",
        "    predicted_labels = []\n",
        "    docwise_predicted_labels=[]\n",
        "    docwise_true_labels = []\n",
        "    doc_name_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in eval_batches:\n",
        "            # move tensor to gpu\n",
        "            shift_to_device(batch,device)\n",
        "\n",
        "            output = model(batch=batch, eval=True)\n",
        "            \n",
        "            for each in range(len(batch['doc_name'])):\n",
        "                true_labels_batch, predicted_labels_batch = \\\n",
        "                    clear_and_map_padded_values(batch[\"label_ids\"][each], output[id][each],label_to_ind)\n",
        "                assert len(batch['sentence_mask'][each].nonzero()) == len(predicted_labels_batch)\n",
        "\n",
        "                #print(batch[\"label_ids\"][each].shape, output['predicted_label'][each].shape)\n",
        "                #print(len(true_labels_batch), len(predicted_labels_batch))\n",
        "                #print(batch['doc_name'][each])\n",
        "                docwise_true_labels.append(true_labels_batch)\n",
        "                docwise_predicted_labels.append(predicted_labels_batch)\n",
        "                doc_name_list.append(batch['doc_name'][each])\n",
        "                true_labels.extend(true_labels_batch)\n",
        "                predicted_labels.extend(predicted_labels_batch)\n",
        "            \n",
        "            shift_to_device(batch,torch.device(\"cpu\"))\n",
        "    \n",
        "    labels_dict['y_true']=true_labels\n",
        "    labels_dict['y_predicted'] = predicted_labels\n",
        "    labels_dict['docwise_y_true'] = docwise_true_labels\n",
        "    labels_dict['docwise_y_predicted'] = docwise_predicted_labels\n",
        "    labels_dict['doc_names'] = doc_name_list\n",
        "    metrics, confusion, class_report = \\\n",
        "        calc_classification_metrics(y_true=true_labels, y_predicted=predicted_labels,labels = list(label_to_ind.keys()))\n",
        "    return metrics, confusion,labels_dict, class_report\n",
        "    \n",
        "    \n",
        "def clear_and_map_padded_values(true_labels, predicted_labels,label_to_ind):\n",
        "    cleared_predicted = []\n",
        "    cleared_true = []\n",
        "    ind_to_label = {v: k for k, v in label_to_ind.items()}\n",
        "    for true_label, predicted_label in zip(true_labels, predicted_labels):\n",
        "        if true_label.item() != label_to_ind['MASK']:\n",
        "            cleared_true.append(ind_to_label[true_label.item()])\n",
        "            cleared_predicted.append(ind_to_label[predicted_label.item()])\n",
        "    return cleared_true, cleared_predicted\n",
        "\n",
        "def calc_classification_metrics(y_true, y_predicted, labels):\n",
        "    macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(y_true, y_predicted, average='macro')\n",
        "    micro_precision, micro_recall, micro_f1, _ = precision_recall_fscore_support(y_true, y_predicted, average='micro')\n",
        "    weighted_precision, weighted_recall, weighted_f1, _ = precision_recall_fscore_support(y_true, y_predicted, average='weighted')\n",
        "    per_label_precision, per_label_recall, per_label_f1, _ = precision_recall_fscore_support(y_true, y_predicted, average=None, labels=labels)\n",
        "\n",
        "    #print(\"TRUE----LEN------ \", len(y_true), \"----\", y_true)\n",
        "\n",
        "    true_span_labels = [x[0] for x in groupby(y_true)]\n",
        "    \n",
        "    pred_span_labels = [x[0] for x in groupby(y_predicted)]\n",
        "\n",
        "    (pred_span_labels.extend([0] * (len(true_span_labels) - len(pred_span_labels)))) if (len(true_span_labels) > len(pred_span_labels)) else (true_span_labels.extend([0] * (len(pred_span_labels) - len(true_span_labels))))\n",
        "\n",
        "    span_result = [1 for i, j in zip(true_span_labels, pred_span_labels) if i == j]\n",
        "\n",
        "    span_F1 = len(span_result) / len(true_span_labels)\n",
        "\n",
        "    print(\"TRUE SPANS*******\", len(true_span_labels), \"****\", true_span_labels) \n",
        "    print(\"PREDICTED----------\", len(pred_span_labels), \"----\", pred_span_labels)\n",
        "    print(\"SPAN RES##########\", len(span_result), \"######\", span_result, \"########\", span_F1)\n",
        "    \n",
        "\n",
        "    acc = accuracy_score(y_true, y_predicted)\n",
        "\n",
        "    class_report = classification_report(y_true, y_predicted, digits=4)\n",
        "    confusion_abs = confusion_matrix(y_true, y_predicted, labels=labels)\n",
        "    # normalize confusion matrix\n",
        "    confusion = np.around(confusion_abs.astype('float') / confusion_abs.sum(axis=1)[:, np.newaxis] * 100, 2)\n",
        "    return {\"acc\": acc,\n",
        "            \"macro-f1\": macro_f1,\n",
        "            \"macro-precision\": macro_precision,\n",
        "            \"macro-recall\": macro_recall,\n",
        "            \"micro-f1\": micro_f1,\n",
        "            \"micro-precision\": micro_precision,\n",
        "            \"micro-recall\": micro_recall,\n",
        "            \"weighted-f1\": weighted_f1,\n",
        "            \"weighted-precision\": weighted_precision,\n",
        "            \"weighted-recall\": weighted_recall,\n",
        "            \"labels\": labels,\n",
        "            \"per-label-f1\": per_label_f1.tolist(),\n",
        "            \"per-label-precision\": per_label_precision.tolist(),\n",
        "            \"per-label-recall\": per_label_recall.tolist(),\n",
        "            \"confusion_abs\": confusion_abs.tolist()\n",
        "            }, \\\n",
        "           confusion.tolist(), \\\n",
        "           class_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "6TlmMAabCjMP"
      },
      "outputs": [],
      "source": [
        "def shift_to_device(batch,device):\n",
        "  for key in batch.keys():\n",
        "    if(torch.is_tensor(batch[key])):\n",
        "      batch[key] = batch[key].to(device)\n",
        "    else:\n",
        "      batch[key] = batch[key]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o36lYyNQDZ4i",
        "outputId": "dbf8d726-5ede-444b-bfff-cbdf68cbd910"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 0 / 10]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss in epoch 0 : 27.328601837158203\n",
            "TRUE SPANS******* 15 **** ['BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS', 'BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS', 'BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS']\n",
            "PREDICTED---------- 15 ---- ['BACKGROUND', 'METHODS', 'CONCLUSIONS', 'BACKGROUND', 'METHODS', 'CONCLUSIONS', 'BACKGROUND', 'METHODS', 'CONCLUSIONS', 0, 0, 0, 0, 0, 0]\n",
            "SPAN RES########## 2 ###### [1, 1] ######## 0.13333333333333333\n",
            "{'acc': 0.53125, 'macro-f1': 0.41764411027568926, 'macro-precision': 0.3333333333333333, 'macro-recall': 0.5666666666666667, 'micro-f1': 0.53125, 'micro-precision': 0.53125, 'micro-recall': 0.53125, 'weighted-f1': 0.38916040100250626, 'weighted-precision': 0.3092948717948718, 'weighted-recall': 0.53125, 'labels': ['MASK', 'OBJECTIVE', 'BACKGROUND', 'METHODS', 'RESULTS', 'CONCLUSIONS', 'START', 'STOP'], 'per-label-f1': [0.0, 0.0, 0.761904761904762, 0.5263157894736842, 0.0, 0.8, 0.0, 0.0], 'per-label-precision': [0.0, 0.0, 0.6153846153846154, 0.38461538461538464, 0.0, 0.6666666666666666, 0.0, 0.0], 'per-label-recall': [0.0, 0.0, 1.0, 0.8333333333333334, 0.0, 1.0, 0.0, 0.0], 'confusion_abs': [[0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 4, 0, 0, 0, 0, 0], [0, 0, 8, 0, 0, 0, 0, 0], [0, 0, 1, 5, 0, 0, 0, 0], [0, 0, 0, 8, 0, 2, 0, 0], [0, 0, 0, 0, 0, 4, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]]}\n",
            "[Epoch 1 / 10]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss in epoch 1 : 25.86196517944336\n",
            "TRUE SPANS******* 15 **** ['BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS', 'BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS', 'BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS']\n",
            "PREDICTED---------- 15 ---- ['BACKGROUND', 'METHODS', 'CONCLUSIONS', 'OBJECTIVE', 'BACKGROUND', 'METHODS', 'CONCLUSIONS', 'OBJECTIVE', 'BACKGROUND', 'METHODS', 'CONCLUSIONS', 0, 0, 0, 0]\n",
            "SPAN RES########## 1 ###### [1] ######## 0.06666666666666667\n",
            "{'acc': 0.4375, 'macro-f1': 0.3688888888888889, 'macro-precision': 0.29999999999999993, 'macro-recall': 0.4833333333333333, 'micro-f1': 0.4375, 'micro-precision': 0.4375, 'micro-recall': 0.4375, 'weighted-f1': 0.3333333333333333, 'weighted-precision': 0.2708333333333333, 'weighted-recall': 0.4375, 'labels': ['MASK', 'OBJECTIVE', 'BACKGROUND', 'METHODS', 'RESULTS', 'CONCLUSIONS', 'START', 'STOP'], 'per-label-f1': [0.0, 0.0, 0.6, 0.4444444444444444, 0.0, 0.8, 0.0, 0.0], 'per-label-precision': [0.0, 0.0, 0.5, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.0], 'per-label-recall': [0.0, 0.0, 0.75, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0], 'confusion_abs': [[0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 4, 0, 0, 0, 0, 0], [0, 2, 6, 0, 0, 0, 0, 0], [0, 0, 2, 4, 0, 0, 0, 0], [0, 0, 0, 8, 0, 2, 0, 0], [0, 0, 0, 0, 0, 4, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]]}\n",
            "[Epoch 2 / 10]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss in epoch 2 : 20.72900390625\n",
            "TRUE SPANS******* 15 **** ['BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS', 'BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS', 'BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS']\n",
            "PREDICTED---------- 15 ---- ['OBJECTIVE', 'BACKGROUND', 'METHODS', 'CONCLUSIONS', 'OBJECTIVE', 'BACKGROUND', 'METHODS', 'CONCLUSIONS', 'OBJECTIVE', 'BACKGROUND', 'METHODS', 'CONCLUSIONS', 0, 0, 0]\n",
            "SPAN RES########## 2 ###### [1, 1] ######## 0.13333333333333333\n",
            "{'acc': 0.375, 'macro-f1': 0.33090909090909093, 'macro-precision': 0.2714285714285714, 'macro-recall': 0.425, 'micro-f1': 0.375, 'micro-precision': 0.375, 'micro-recall': 0.375, 'weighted-f1': 0.28863636363636364, 'weighted-precision': 0.23511904761904762, 'weighted-recall': 0.375, 'labels': ['MASK', 'OBJECTIVE', 'BACKGROUND', 'METHODS', 'RESULTS', 'CONCLUSIONS', 'START', 'STOP'], 'per-label-f1': [0.0, 0.0, 0.45454545454545453, 0.4, 0.0, 0.8, 0.0, 0.0], 'per-label-precision': [0.0, 0.0, 0.35714285714285715, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.0], 'per-label-recall': [0.0, 0.0, 0.625, 0.5, 0.0, 1.0, 0.0, 0.0], 'confusion_abs': [[0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 4, 0, 0, 0, 0, 0], [0, 3, 5, 0, 0, 0, 0, 0], [0, 0, 3, 3, 0, 0, 0, 0], [0, 0, 2, 6, 0, 2, 0, 0], [0, 0, 0, 0, 0, 4, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]]}\n",
            "[Epoch 3 / 10]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss in epoch 3 : 20.367755889892578\n",
            "TRUE SPANS******* 20 **** ['BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS', 'BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS', 'BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS', 0, 0, 0, 0, 0]\n",
            "PREDICTED---------- 20 ---- ['OBJECTIVE', 'RESULTS', 'OBJECTIVE', 'RESULTS', 'OBJECTIVE', 'RESULTS', 'OBJECTIVE', 'RESULTS', 'OBJECTIVE', 'RESULTS', 'OBJECTIVE', 'BACKGROUND', 'METHODS', 'CONCLUSIONS', 'OBJECTIVE', 'RESULTS', 'OBJECTIVE', 'BACKGROUND', 'METHODS', 'CONCLUSIONS']\n",
            "SPAN RES########## 3 ###### [1, 1, 1] ######## 0.15\n",
            "{'acc': 0.3125, 'macro-f1': 0.35311942959001785, 'macro-precision': 0.3621428571428571, 'macro-recall': 0.35666666666666663, 'micro-f1': 0.3125, 'micro-precision': 0.3125, 'micro-recall': 0.3125, 'weighted-f1': 0.3187945632798574, 'weighted-precision': 0.33616071428571426, 'weighted-recall': 0.3125, 'labels': ['MASK', 'OBJECTIVE', 'BACKGROUND', 'METHODS', 'RESULTS', 'CONCLUSIONS', 'START', 'STOP'], 'per-label-f1': [0.0, 0.16666666666666666, 0.25, 0.3636363636363636, 0.23529411764705882, 0.75, 0.0, 0.0], 'per-label-precision': [0.0, 0.125, 0.25, 0.4, 0.2857142857142857, 0.75, 0.0, 0.0], 'per-label-recall': [0.0, 0.25, 0.25, 0.3333333333333333, 0.2, 0.75, 0.0, 0.0], 'confusion_abs': [[0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 2, 0, 1, 0, 0, 0], [0, 4, 2, 0, 2, 0, 0, 0], [0, 1, 2, 2, 1, 0, 0, 0], [0, 2, 2, 3, 2, 1, 0, 0], [0, 0, 0, 0, 1, 3, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]]}\n",
            "[Epoch 4 / 10]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss in epoch 4 : 17.457311630249023\n",
            "TRUE SPANS******* 15 **** ['BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS', 'BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS', 'BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS']\n",
            "PREDICTED---------- 15 ---- ['OBJECTIVE', 'BACKGROUND', 'METHODS', 'CONCLUSIONS', 'OBJECTIVE', 'BACKGROUND', 'METHODS', 'CONCLUSIONS', 'OBJECTIVE', 'BACKGROUND', 'METHODS', 'CONCLUSIONS', 0, 0, 0]\n",
            "SPAN RES########## 2 ###### [1, 1] ######## 0.13333333333333333\n",
            "{'acc': 0.375, 'macro-f1': 0.3302380952380953, 'macro-precision': 0.2702564102564103, 'macro-recall': 0.425, 'micro-f1': 0.375, 'micro-precision': 0.375, 'micro-recall': 0.375, 'weighted-f1': 0.28936011904761905, 'weighted-precision': 0.23573717948717948, 'weighted-recall': 0.375, 'labels': ['MASK', 'OBJECTIVE', 'BACKGROUND', 'METHODS', 'RESULTS', 'CONCLUSIONS', 'START', 'STOP'], 'per-label-f1': [0.0, 0.0, 0.4761904761904762, 0.37499999999999994, 0.0, 0.8, 0.0, 0.0], 'per-label-precision': [0.0, 0.0, 0.38461538461538464, 0.3, 0.0, 0.6666666666666666, 0.0, 0.0], 'per-label-recall': [0.0, 0.0, 0.625, 0.5, 0.0, 1.0, 0.0, 0.0], 'confusion_abs': [[0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 4, 0, 0, 0, 0, 0], [0, 3, 5, 0, 0, 0, 0, 0], [0, 0, 3, 3, 0, 0, 0, 0], [0, 0, 1, 7, 0, 2, 0, 0], [0, 0, 0, 0, 0, 4, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]]}\n",
            "[Epoch 5 / 10]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss in epoch 5 : 18.330059051513672\n",
            "TRUE SPANS******* 15 **** ['BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS', 'BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS', 'BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS']\n",
            "PREDICTED---------- 15 ---- ['OBJECTIVE', 'RESULTS', 'OBJECTIVE', 'BACKGROUND', 'METHODS', 'CONCLUSIONS', 'OBJECTIVE', 'BACKGROUND', 'METHODS', 'CONCLUSIONS', 'OBJECTIVE', 'BACKGROUND', 'METHODS', 'CONCLUSIONS', 0]\n",
            "SPAN RES########## 3 ###### [1, 1, 1] ######## 0.2\n",
            "{'acc': 0.375, 'macro-f1': 0.37, 'macro-precision': 0.31666666666666665, 'macro-recall': 0.45, 'micro-f1': 0.375, 'micro-precision': 0.375, 'micro-recall': 0.375, 'weighted-f1': 0.30625, 'weighted-precision': 0.26041666666666663, 'weighted-recall': 0.375, 'labels': ['MASK', 'OBJECTIVE', 'BACKGROUND', 'METHODS', 'RESULTS', 'CONCLUSIONS', 'START', 'STOP'], 'per-label-f1': [0.0, 0.25, 0.4, 0.4, 0.0, 0.8, 0.0, 0.0], 'per-label-precision': [0.0, 0.25, 0.3333333333333333, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.0], 'per-label-recall': [0.0, 0.25, 0.5, 0.5, 0.0, 1.0, 0.0, 0.0], 'confusion_abs': [[0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 3, 0, 0, 0, 0, 0], [0, 3, 4, 0, 1, 0, 0, 0], [0, 0, 3, 3, 0, 0, 0, 0], [0, 0, 2, 6, 0, 2, 0, 0], [0, 0, 0, 0, 0, 4, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]]}\n",
            "[Epoch 6 / 10]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss in epoch 6 : 15.045729637145996\n",
            "TRUE SPANS******* 18 **** ['BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS', 'BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS', 'BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS', 0, 0, 0]\n",
            "PREDICTED---------- 18 ---- ['OBJECTIVE', 'RESULTS', 'OBJECTIVE', 'BACKGROUND', 'METHODS', 'CONCLUSIONS', 'OBJECTIVE', 'BACKGROUND', 'OBJECTIVE', 'BACKGROUND', 'METHODS', 'CONCLUSIONS', 'OBJECTIVE', 'RESULTS', 'OBJECTIVE', 'BACKGROUND', 'METHODS', 'CONCLUSIONS']\n",
            "SPAN RES########## 2 ###### [1, 1] ######## 0.1111111111111111\n",
            "{'acc': 0.28125, 'macro-f1': 0.32987012987012987, 'macro-precision': 0.2871428571428571, 'macro-recall': 0.39166666666666666, 'micro-f1': 0.28125, 'micro-precision': 0.28125, 'micro-recall': 0.28125, 'weighted-f1': 0.2379148629148629, 'weighted-precision': 0.2075892857142857, 'weighted-recall': 0.28125, 'labels': ['MASK', 'OBJECTIVE', 'BACKGROUND', 'METHODS', 'RESULTS', 'CONCLUSIONS', 'START', 'STOP'], 'per-label-f1': [0.0, 0.36363636363636365, 0.11111111111111112, 0.28571428571428575, 0.0, 0.888888888888889, 0.0, 0.0], 'per-label-precision': [0.0, 0.2857142857142857, 0.1, 0.25, 0.0, 0.8, 0.0, 0.0], 'per-label-recall': [0.0, 0.5, 0.125, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0], 'confusion_abs': [[0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 2, 0, 0, 0, 0, 0], [0, 5, 1, 0, 2, 0, 0, 0], [0, 0, 4, 2, 0, 0, 0, 0], [0, 0, 3, 6, 0, 1, 0, 0], [0, 0, 0, 0, 0, 4, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]]}\n",
            "[Epoch 7 / 10]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss in epoch 7 : 16.771116256713867\n",
            "TRUE SPANS******* 15 **** ['BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS', 'BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS', 'BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS']\n",
            "PREDICTED---------- 15 ---- ['OBJECTIVE', 'BACKGROUND', 'METHODS', 'CONCLUSIONS', 'OBJECTIVE', 'BACKGROUND', 'METHODS', 'CONCLUSIONS', 'OBJECTIVE', 'BACKGROUND', 'METHODS', 'CONCLUSIONS', 0, 0, 0]\n",
            "SPAN RES########## 2 ###### [1, 1] ######## 0.13333333333333333\n",
            "{'acc': 0.375, 'macro-f1': 0.3302380952380953, 'macro-precision': 0.2702564102564103, 'macro-recall': 0.425, 'micro-f1': 0.375, 'micro-precision': 0.375, 'micro-recall': 0.375, 'weighted-f1': 0.28936011904761905, 'weighted-precision': 0.23573717948717948, 'weighted-recall': 0.375, 'labels': ['MASK', 'OBJECTIVE', 'BACKGROUND', 'METHODS', 'RESULTS', 'CONCLUSIONS', 'START', 'STOP'], 'per-label-f1': [0.0, 0.0, 0.4761904761904762, 0.37499999999999994, 0.0, 0.8, 0.0, 0.0], 'per-label-precision': [0.0, 0.0, 0.38461538461538464, 0.3, 0.0, 0.6666666666666666, 0.0, 0.0], 'per-label-recall': [0.0, 0.0, 0.625, 0.5, 0.0, 1.0, 0.0, 0.0], 'confusion_abs': [[0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 4, 0, 0, 0, 0, 0], [0, 3, 5, 0, 0, 0, 0, 0], [0, 0, 3, 3, 0, 0, 0, 0], [0, 0, 1, 7, 0, 2, 0, 0], [0, 0, 0, 0, 0, 4, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]]}\n",
            "[Epoch 8 / 10]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss in epoch 8 : 18.429733276367188\n",
            "TRUE SPANS******* 15 **** ['BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS', 'BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS', 'BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS']\n",
            "PREDICTED---------- 15 ---- ['OBJECTIVE', 'RESULTS', 'OBJECTIVE', 'BACKGROUND', 'METHODS', 'CONCLUSIONS', 'BACKGROUND', 'METHODS', 'CONCLUSIONS', 'OBJECTIVE', 'BACKGROUND', 'METHODS', 'CONCLUSIONS', 0, 0]\n",
            "SPAN RES########## 2 ###### [1, 1] ######## 0.13333333333333333\n",
            "{'acc': 0.3125, 'macro-f1': 0.30383838383838385, 'macro-precision': 0.26158730158730165, 'macro-recall': 0.36666666666666664, 'micro-f1': 0.3125, 'micro-precision': 0.3125, 'micro-recall': 0.3125, 'weighted-f1': 0.25202020202020203, 'weighted-precision': 0.2130952380952381, 'weighted-recall': 0.3125, 'labels': ['MASK', 'OBJECTIVE', 'BACKGROUND', 'METHODS', 'RESULTS', 'CONCLUSIONS', 'START', 'STOP'], 'per-label-f1': [0.0, 0.0, 0.36363636363636365, 0.26666666666666666, 0.0, 0.888888888888889, 0.0, 0.0], 'per-label-precision': [0.0, 0.0, 0.2857142857142857, 0.2222222222222222, 0.0, 0.8, 0.0, 0.0], 'per-label-recall': [0.0, 0.0, 0.5, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0], 'confusion_abs': [[0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 4, 0, 0, 0, 0, 0], [0, 3, 4, 0, 1, 0, 0, 0], [0, 0, 4, 2, 0, 0, 0, 0], [0, 0, 2, 7, 0, 1, 0, 0], [0, 0, 0, 0, 0, 4, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]]}\n",
            "[Epoch 9 / 10]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss in epoch 9 : 15.723823547363281\n",
            "TRUE SPANS******* 15 **** ['BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS', 'BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS', 'BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS']\n",
            "PREDICTED---------- 15 ---- ['BACKGROUND', 'OBJECTIVE', 'BACKGROUND', 'METHODS', 'CONCLUSIONS', 'OBJECTIVE', 'BACKGROUND', 'METHODS', 'CONCLUSIONS', 'OBJECTIVE', 'BACKGROUND', 'METHODS', 'CONCLUSIONS', 0, 0]\n",
            "SPAN RES########## 5 ###### [1, 1, 1, 1, 1] ######## 0.3333333333333333\n",
            "{'acc': 0.34375, 'macro-f1': 0.36764790764790767, 'macro-precision': 0.31714285714285717, 'macro-recall': 0.4416666666666666, 'micro-f1': 0.34375, 'micro-precision': 0.34375, 'micro-recall': 0.34375, 'weighted-f1': 0.28513708513708513, 'weighted-precision': 0.24508928571428573, 'weighted-recall': 0.34375, 'labels': ['MASK', 'OBJECTIVE', 'BACKGROUND', 'METHODS', 'RESULTS', 'CONCLUSIONS', 'START', 'STOP'], 'per-label-f1': [0.0, 0.36363636363636365, 0.3, 0.28571428571428575, 0.0, 0.888888888888889, 0.0, 0.0], 'per-label-precision': [0.0, 0.2857142857142857, 0.25, 0.25, 0.0, 0.8, 0.0, 0.0], 'per-label-recall': [0.0, 0.5, 0.375, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0], 'confusion_abs': [[0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 2, 0, 0, 0, 0, 0], [0, 5, 3, 0, 0, 0, 0, 0], [0, 0, 4, 2, 0, 0, 0, 0], [0, 0, 3, 6, 0, 1, 0, 0], [0, 0, 0, 0, 0, 4, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]]}\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
        "import itertools\n",
        "import gc\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "num_epochs = 10\n",
        "learning_rate = 3e-4\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = BertHSLN(config).to(device)\n",
        "\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "  if(\"bert\" in name):\n",
        "    param.requires_grad = False\n",
        "\n",
        "optimizer = optim.Adam(list(filter(lambda p: p.requires_grad, model.parameters())), lr=learning_rate)\n",
        "max_grad_norm = 1.0\n",
        "epoch_scheduler = StepLR(optimizer, step_size=1, gamma=config[\"lr_epoch_decay\"])\n",
        "\n",
        "accs = []\n",
        "epochs = []\n",
        "train_losses = []\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
        "    model.train()\n",
        "    for batch_idx, batch in tqdm(enumerate(train_dataloader),total=len(train_dataloader), leave=False):\n",
        "        shift_to_device(batch,device)\n",
        "        output = model(batch, batch[\"label_ids\"])\n",
        "        loss = output[\"loss2\"]\n",
        "        #loss = output[\"loss1\"] + output[\"loss2\"]\n",
        "        loss = loss.sum()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        shift_to_device(batch,torch.device(\"cpu\"))\n",
        "    \n",
        "    epochs.append(epoch)\n",
        "    train_losses.append(loss.item())\n",
        "    print(f\"Loss in epoch {epoch} : {loss.item()}\")\n",
        "    epoch_scheduler.step()\n",
        "\n",
        "    #test_metrics, test_confusion,labels_dict,_ = eval_model(model, dev_dataloader , device,label_to_ind,\"predicted_label1\")\n",
        "    #print(test_metrics)\n",
        "    test_metrics, test_confusion,labels_dict,_ = eval_model(model, dev_dataloader , device,label_to_ind,\"predicted_label2\")\n",
        "    accs.append(test_metrics['acc'])\n",
        "    print(test_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#PahPre macroF1 0.32 acc: 0.58 Epoch: 25 span len: 2\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(epochs, train_losses)\n",
        "plt.ylabel('Train loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(epochs, accs)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JN1ZB0cH5rXS"
      },
      "outputs": [],
      "source": [
        "#Paheli macroF1 0.19777 acc: 0.42 Epoch: 31 span len: 10\n",
        "#PahPre macroF1 0.19371 acc: 0.42 Epoch: 50 span len: 10\n",
        "\n",
        "#PahPre macroF1 0.32 acc: 0.58 Epoch: 25 span len: 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFf2Y3pshr-V"
      },
      "outputs": [],
      "source": [
        "#Ekstep Span 2 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(epochs, train_losses)\n",
        "plt.ylabel('Train loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(epochs, accs)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qbckx4Xq5BGe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "RRL.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b9e4c39c525435a94c7884d74877403": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12fed375ae214b879e919e41ccd4cf33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13c2b694dc4941afaf235b58f20aa85f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18f1695e3eda42d58f2ecdd0c3ab9426",
              "IPY_MODEL_c6eb73c1e7444f6083b441ffe3400e12",
              "IPY_MODEL_8f9005acf79243a189fcfbe2b1eac624"
            ],
            "layout": "IPY_MODEL_98fe32532a304a8282add6b25c52d1c7"
          }
        },
        "15acdcb1cc094ff6963cf2f0a16eacc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de1b76926b6748189defe4746d2f8c6f",
            "placeholder": "​",
            "style": "IPY_MODEL_891b5b5ba0124b3f935b01c2f29adb8e",
            "value": "Downloading: 100%"
          }
        },
        "1876d10c710f4568ab0878d384bd3b3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e3388cc950f40e4aa5c45dbeeab8c33",
            "placeholder": "​",
            "style": "IPY_MODEL_27569f0920204db693743a7dd7334fc4",
            "value": "Downloading: 100%"
          }
        },
        "18f1695e3eda42d58f2ecdd0c3ab9426": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f874b0d9b25744479398d7cfafcc12c7",
            "placeholder": "​",
            "style": "IPY_MODEL_e3e47c039f4b4804a6276a7d0d08feaf",
            "value": "Downloading: 100%"
          }
        },
        "263dda38a56b4073ac4ec6b45336638e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27569f0920204db693743a7dd7334fc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a90ab1229dc45f888a2975f298fe7e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e3388cc950f40e4aa5c45dbeeab8c33": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f772cb95b4b49a18f1c2379d1aed87c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3509bd32bfc149c5a1463668a8cd44ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f143abfb81a4a45b377bd1d93b7c52b",
            "placeholder": "​",
            "style": "IPY_MODEL_c64cc81f9cc34392bfe3c0867abb0d34",
            "value": " 226k/226k [00:00&lt;00:00, 186kB/s]"
          }
        },
        "36794b1c84fd476db7314087a16466c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1876d10c710f4568ab0878d384bd3b3d",
              "IPY_MODEL_e8c22a2edae6401da6d385d9e908b793",
              "IPY_MODEL_e0bdbe69ba55494fa8cb6e5e51f12785"
            ],
            "layout": "IPY_MODEL_41d2e3d7dca64f4a8c5c8250168d6c2a"
          }
        },
        "38dbeaa7298a492c9a9f5648ea60f805": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c497772474e4a87b61af44d840c8d33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4024b058295140e682ea95b872faddff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41d2e3d7dca64f4a8c5c8250168d6c2a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47567b7609aa48078c0a5bf9698a9329": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51b0e2f45a8d4e3eab815aa402883962": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53ab88f470d54bd5adbf3f9f4bec13d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64c8f3ca1b0f449dabb520b93027ddf1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "674889cd6cf34a7fa258e8420a2d1f37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4f4e842d8b14f62b1733d4dc89277ea",
              "IPY_MODEL_88699d07a5174e41ba6bfa0ee75f8ac7",
              "IPY_MODEL_cfab0efd04824078b75c96c55076161f"
            ],
            "layout": "IPY_MODEL_fba628e888bb485cbf54f1bd5283a4be"
          }
        },
        "6f143abfb81a4a45b377bd1d93b7c52b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c1dc6d4c0d74929aa92e8608095dd0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b9e4c39c525435a94c7884d74877403",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c497772474e4a87b61af44d840c8d33",
            "value": 231508
          }
        },
        "7cf7e2a774044bfd886effd679486b10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88699d07a5174e41ba6bfa0ee75f8ac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df14c414329c40d7a3736fbf8d6a03e2",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_53ab88f470d54bd5adbf3f9f4bec13d1",
            "value": 28
          }
        },
        "891b5b5ba0124b3f935b01c2f29adb8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f9005acf79243a189fcfbe2b1eac624": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a90ab1229dc45f888a2975f298fe7e0",
            "placeholder": "​",
            "style": "IPY_MODEL_bbb4d83a7d9e4d41b7ab47fae0e5ea83",
            "value": " 570/570 [00:00&lt;00:00, 17.7kB/s]"
          }
        },
        "92e5cc5aa19f4c368aaa48e844751932": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c1f102b475e4ebeae72a5959444b295",
              "IPY_MODEL_eb7010c4f9e044868a9b6bf560edb733",
              "IPY_MODEL_c950d5c21ecd4c5db09d7eeb23a00d37"
            ],
            "layout": "IPY_MODEL_e24b0f412eec41a490bc1fea71ac2ea8"
          }
        },
        "98fe32532a304a8282add6b25c52d1c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99660b96a3c641ab8b1f318763a67c8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15acdcb1cc094ff6963cf2f0a16eacc1",
              "IPY_MODEL_7c1dc6d4c0d74929aa92e8608095dd0d",
              "IPY_MODEL_3509bd32bfc149c5a1463668a8cd44ab"
            ],
            "layout": "IPY_MODEL_51b0e2f45a8d4e3eab815aa402883962"
          }
        },
        "9a860322edaa4d0f8cb0092f1e44cf92": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c1f102b475e4ebeae72a5959444b295": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f772cb95b4b49a18f1c2379d1aed87c",
            "placeholder": "​",
            "style": "IPY_MODEL_4024b058295140e682ea95b872faddff",
            "value": "  0%"
          }
        },
        "b731b848ded444ffa79b23fbcc2bdc1d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b73335e747ce4270b4986d592169932f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbb4d83a7d9e4d41b7ab47fae0e5ea83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4f4e842d8b14f62b1733d4dc89277ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64c8f3ca1b0f449dabb520b93027ddf1",
            "placeholder": "​",
            "style": "IPY_MODEL_7cf7e2a774044bfd886effd679486b10",
            "value": "Downloading: 100%"
          }
        },
        "c64cc81f9cc34392bfe3c0867abb0d34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6eb73c1e7444f6083b441ffe3400e12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9c7e1fdf45b4defa924d71274ab1d3a",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed79e8dda8484edda93cdb368fff3949",
            "value": 570
          }
        },
        "c950d5c21ecd4c5db09d7eeb23a00d37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_263dda38a56b4073ac4ec6b45336638e",
            "placeholder": "​",
            "style": "IPY_MODEL_ce33d78ec6a24a2ea60c8a29e505bf42",
            "value": " 0/5 [00:00&lt;?, ?it/s]"
          }
        },
        "c9c7e1fdf45b4defa924d71274ab1d3a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce33d78ec6a24a2ea60c8a29e505bf42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfab0efd04824078b75c96c55076161f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d639947914e84548b8b4bf8eb0ef3c5d",
            "placeholder": "​",
            "style": "IPY_MODEL_b73335e747ce4270b4986d592169932f",
            "value": " 28.0/28.0 [00:00&lt;00:00, 810B/s]"
          }
        },
        "d639947914e84548b8b4bf8eb0ef3c5d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de1b76926b6748189defe4746d2f8c6f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df14c414329c40d7a3736fbf8d6a03e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0bdbe69ba55494fa8cb6e5e51f12785": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b731b848ded444ffa79b23fbcc2bdc1d",
            "placeholder": "​",
            "style": "IPY_MODEL_12fed375ae214b879e919e41ccd4cf33",
            "value": " 455k/455k [00:01&lt;00:00, 494kB/s]"
          }
        },
        "e24b0f412eec41a490bc1fea71ac2ea8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3e47c039f4b4804a6276a7d0d08feaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8c22a2edae6401da6d385d9e908b793": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb940d745a404485871911c35b7136ba",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a860322edaa4d0f8cb0092f1e44cf92",
            "value": 466062
          }
        },
        "eb7010c4f9e044868a9b6bf560edb733": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47567b7609aa48078c0a5bf9698a9329",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38dbeaa7298a492c9a9f5648ea60f805",
            "value": 0
          }
        },
        "ed79e8dda8484edda93cdb368fff3949": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f874b0d9b25744479398d7cfafcc12c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb940d745a404485871911c35b7136ba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fba628e888bb485cbf54f1bd5283a4be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
